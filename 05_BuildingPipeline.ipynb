{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05.BuildingPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsV/nDpJJcNGkSz/JYpUpD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/05_BuildingPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck61xWWitahp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJik6jm0niEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234343b3-eba3-47e3-b67b-d52379aaa6d3"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([5,5,4,1,5,2])\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WIiwLJ2tY9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940f88f3-8aaf-42cb-b74c-d5900b99b9b2"
      },
      "source": [
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "4\n",
            "1\n",
            "5\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOEbgvKZvNth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee78145-a2ee-4b1d-eb25-e11c25ec9654"
      },
      "source": [
        "it = iter(dataset)\n",
        "print(next(it).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Br3yXOyvskr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558b881d-6f31-4dde-d311-38b3a02756cc"
      },
      "source": [
        "print(dataset.reduce(0, lambda state, value : state + value).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjctm-PqwZLh"
      },
      "source": [
        "### **Dataset structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EU-my4RwTKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b169770a-99a4-41e7-b5e9-2aa8f2a388e1"
      },
      "source": [
        "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4,10]))\n",
        "dataset1.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(10,), dtype=tf.float32, name=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk-Ip7tiTQiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e9d258-961d-4f86-91b7-633fadbc1f92"
      },
      "source": [
        "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4,100],maxval=100, dtype=tf.int32))\n",
        ")\n",
        "dataset2.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF1779c8XDs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95967a2-4b5a-4f99-ae4d-b1c8ee5ab12c"
      },
      "source": [
        "dataset3 = tf.data.Dataset.zip((dataset1,dataset2))\n",
        "dataset3.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
              " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGFRGI6AUsAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780834f4-676f-4c8d-b904-70195f516aae"
      },
      "source": [
        "# Dataset containing a sparse tensor\n",
        "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0,0],[1,2]], values=[1,2], dense_shape=[3,4]))\n",
        "\n",
        "dataset4.element_spec\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseTensorSpec(TensorShape([3, 4]), tf.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1IHMhg2Vkty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e1775c-51a0-49dc-b1e2-f002e6cd62bc"
      },
      "source": [
        "#use value_type to see the type of value represented by the element spec\n",
        "dataset4.element_spec.value_type\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.sparse_tensor.SparseTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlf8_nL9XgJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc355ae5-e4b3-441e-dfd0-68ebc8d9cb50"
      },
      "source": [
        "dataset1 = tf.data.Dataset.from_tensor_slices(\n",
        "    tf.random.uniform([4,10], minval=1,maxval=10,dtype = tf.int32)\n",
        ")\n",
        "dataset1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (10,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U32EdfH1Whak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e390a93-59ba-4757-fbb6-17d05f493867"
      },
      "source": [
        "for z in dataset1:\n",
        "  print(z.numpy())\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 6 3 4 3 1 3 9 6 5]\n",
            "[5 2 7 5 3 2 5 7 7 3]\n",
            "[1 1 7 7 7 2 1 2 3 4]\n",
            "[5 6 6 7 4 7 6 2 7 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS1rwAifZxLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436add66-1dbe-4f42-be70-5c43034c8b1e"
      },
      "source": [
        "Dataset2 = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4,100], maxval=100, dtype=tf.int32))\n",
        ")\n",
        "dataset2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (100,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT2877aLaf6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae7295c-8e93-48de-b17a-dd23d3a2ac7c"
      },
      "source": [
        "dataset3=tf.data.Dataset.zip((dataset1,dataset2))\n",
        "dataset3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ZipDataset shapes: ((10,), ((), (100,))), types: (tf.int32, (tf.float32, tf.int32))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFa9MX7ja8P-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26672b73-bb19-4c71-c2c2-0d95ed32e3e1"
      },
      "source": [
        "for a, (b,c) in dataset3:\n",
        "  print('shapes: {a.shape}, {b.shape}, {c.shape}'.format(a=a, b=b, c=c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shapes: (10,), (), (100,)\n",
            "shapes: (10,), (), (100,)\n",
            "shapes: (10,), (), (100,)\n",
            "shapes: (10,), (), (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egu0EalTcfea"
      },
      "source": [
        "### **Reading input data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZQBlLYoyi_A"
      },
      "source": [
        "Consuming Numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkKEciLUcHjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913684e1-279e-476d-8098-01c10984068b"
      },
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MDnyMNLyrzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ea2ab0-2b96-45c9-cd7c-b60bab104f86"
      },
      "source": [
        "images, labels = train\n",
        "images = images/255\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.float64, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPlue57_zZob"
      },
      "source": [
        "Conssuming Python generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGUqRc9qzT_P"
      },
      "source": [
        "def count(stop):\n",
        "  i =0\n",
        "  while i<stop:\n",
        "    yield i\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEtkzhiMz54N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c542a9-2687-4c69-99da-0f6ccd80ab3c"
      },
      "source": [
        "for n in count(5):\n",
        "  print(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQokzzG00Ibs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5968b4c-2eda-4bfd-c67f-61666e6fb222"
      },
      "source": [
        "ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes=(),)\n",
        "ds_counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FlatMapDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VXwk2x-02ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3770ff2-0dc3-44e0-ad86-3eb882f4f1ff"
      },
      "source": [
        "for count_batch in ds_counter.repeat().batch(10).take(10):\n",
        "  print(count_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[10 11 12 13 14 15 16 17 18 19]\n",
            "[20 21 22 23 24  0  1  2  3  4]\n",
            "[ 5  6  7  8  9 10 11 12 13 14]\n",
            "[15 16 17 18 19 20 21 22 23 24]\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[10 11 12 13 14 15 16 17 18 19]\n",
            "[20 21 22 23 24  0  1  2  3  4]\n",
            "[ 5  6  7  8  9 10 11 12 13 14]\n",
            "[15 16 17 18 19 20 21 22 23 24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2vcq5u81krf"
      },
      "source": [
        "def gen_series():\n",
        "  i = 0\n",
        "  while True:\n",
        "    size = np.random.randint(0,10)\n",
        "    yield i, np.random.normal(size=(size,))\n",
        "    i +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyMCOoPX2q5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0311793-4a62-464c-ba61-6c6457900ed2"
      },
      "source": [
        "for i, series in gen_series():\n",
        "  print(i, \":\", str(series))\n",
        "  if i >5:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : [1.54419956 1.41655991]\n",
            "1 : []\n",
            "2 : [-1.47177731  1.28122225  0.47611254 -1.09857556  0.53695867  0.13464602]\n",
            "3 : [0.86423432 1.49255668 2.31316157]\n",
            "4 : [-0.43337892 -0.83019525 -1.19182    -0.15507808  0.1239392  -0.16081916]\n",
            "5 : [-1.28066436  0.22036254  2.04078702  0.95411024 -1.06612376  1.30225528]\n",
            "6 : [ 0.85285236  0.02749249  0.11952706  0.54629505 -0.07288232 -0.35385807]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu0mDkrR414c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c9da71-ed34-47bf-df77-f8e0b7f39e37"
      },
      "source": [
        "ds_series = tf.data.Dataset.from_generator(\n",
        "    gen_series,\n",
        "    output_types=(tf.int32, tf.float32),\n",
        "    output_shapes = ((),(None,))  \n",
        ")\n",
        "ds_series"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FlatMapDataset shapes: ((), (None,)), types: (tf.int32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9h2FBvc6ItQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012d385f-2a66-4a72-8670-f48f510f504b"
      },
      "source": [
        "ds_series_batch = ds_series.shuffle(20).padded_batch(10)\n",
        "\n",
        "ids,sequence_batch = next(iter(ds_series_batch))\n",
        "print(ids.numpy())\n",
        "print()\n",
        "print(sequence_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[16  1  7  5 10 23  2  8 20 15]\n",
            "\n",
            "[[ 0.3087899   1.8356315   1.577824   -0.3799068  -0.32352236  2.6610785\n",
            "  -0.3367504   0.        ]\n",
            " [ 0.49712804  1.3229223   1.1679293   0.2135402   1.0732572  -0.34370953\n",
            "  -0.6063715   0.        ]\n",
            " [ 0.03957643 -1.3862811  -0.5884637   0.2028329   1.0666182  -0.41139233\n",
            "   0.          0.        ]\n",
            " [ 1.8360199   1.7281536  -0.53105974  0.43020478 -1.5893319   1.3242542\n",
            "   0.          0.        ]\n",
            " [-0.4001853   0.01381919  0.          0.          0.          0.\n",
            "   0.          0.        ]\n",
            " [ 0.87876946  0.5502658  -2.3261123   0.93581164 -1.008771   -0.98900694\n",
            "   0.06739069  0.15198636]\n",
            " [ 1.9479853   0.1485789   1.0994276  -0.9851562   0.6651141   0.\n",
            "   0.          0.        ]\n",
            " [-0.6084662  -1.4032997   0.65778726  0.          0.          0.\n",
            "   0.          0.        ]\n",
            " [-0.8060331   1.156996   -1.3831948   0.          0.          0.\n",
            "   0.          0.        ]\n",
            " [-0.6371768   2.2786148  -0.71292573 -0.58691925  2.0967684   0.17653255\n",
            "   0.          0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2THUg8H7Tdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73af7a87-7e5d-4da8-afe0-10a20ab3c14d"
      },
      "source": [
        "#for a more realistic example, try wrapping preprocessing.image.ImageDataGenerator as a tf.data.Dataset.\n",
        "#FIRST DOWNLOAD THE DATA:\n",
        "flowers = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2y8iN3z9h9M"
      },
      "source": [
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,rotation_range = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7XTBExF97z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85046f19-6c8e-4905-f14f-88c9c29fc0f6"
      },
      "source": [
        "images, labels = next(img_gen.flow_from_directory(flowers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3670 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEq5zfje_bAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc39c48-aeb4-40bd-a311-75a9c6b20314"
      },
      "source": [
        "print(images.dtype, images.shape)\n",
        "print(labels.dtype, labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32 (32, 256, 256, 3)\n",
            "float32 (32, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0lu7jf6_uGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6fa3a1-29f8-484c-d48a-b9d46e8c5626"
      },
      "source": [
        "ds = tf.data.Dataset.from_generator(\n",
        "    lambda: img_gen.flow_from_directory(flowers),\n",
        "    output_types = (tf.float32, tf.float32),\n",
        "    output_shapes= ([32,256,256,3],[32,5]),\n",
        ")\n",
        "ds.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(32, 256, 256, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(32, 5), dtype=tf.float32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd2dOYIoB4C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2042e445-9357-454e-da1a-b3d9f5fb8a8c"
      },
      "source": [
        "for images, labels in ds.take(1):\n",
        "  print('images.shapes: ',images.shape)\n",
        "  print('labels.shapes: ',labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3670 images belonging to 5 classes.\n",
            "images.shapes:  (32, 256, 256, 3)\n",
            "labels.shapes:  (32, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUhPO9LLCf93"
      },
      "source": [
        "Consuming TFRecord data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KExQVSANCnu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bb513a-cc6c-4d30-da17-162b6050cef5"
      },
      "source": [
        "#Creates a dataset that reads all of the examples from two files.\n",
        "fsns_test_file = tf.keras.utils.get_file(\"fsns.tfrec\", \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\n",
            "7905280/7904079 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG8VPdqFEtvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74587983-7cc6-4a6b-e15a-e393088e9b44"
      },
      "source": [
        "dataset = tf.data.TFRecordDataset(filenames=[fsns_test_file])\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TFRecordDatasetV2 shapes: (), types: tf.string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab-NrxCXFTvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84861b96-4eff-4142-b98d-9f4b743a2aad"
      },
      "source": [
        "raw_example = next(iter(dataset))\n",
        "parsed = tf.train.Example.FromString(raw_example.numpy())\n",
        "\n",
        "parsed.features.feature['image/text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes_list {\n",
              "  value: \"Rue Perreyon\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEQbzKK6GKF9"
      },
      "source": [
        "Consuming text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_wGp9lOGN81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb73d5a-be79-4f4a-b5cf-b8c24b5d5023"
      },
      "source": [
        "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "file_names = ['cowper.txt','derby.txt','butler.txt']\n",
        "\n",
        "file_path = [tf.keras.utils.get_file(file_name, directory_url + file_name)\n",
        "             for file_name in file_names ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
            "811008/809730 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
            "811008/807992 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Qaus5LNZqa"
      },
      "source": [
        "dataset = tf.data.TextLineDataset(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpZyNZBhOCVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b2f718-b80f-4b45-a5ea-f394edfacb16"
      },
      "source": [
        "#Here are the first few lines of the first file\n",
        "for line in dataset.take(5):\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\"\n",
            "b'His wrath pernicious, who ten thousand woes'\n",
            "b\"Caused to Achaia's host, sent many a soul\"\n",
            "b'Illustrious into Ades premature,'\n",
            "b'And Heroes gave (so stood the will of Jove)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1krkCFyOibY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464e0f56-efe9-45f4-b6ae-87237f546eca"
      },
      "source": [
        "#To alternate lines between files use Datset.interleave. \n",
        "#This makes it easier to shuffle files together. Here are the first,second and third lines from each translation:\n",
        "\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(file_path)\n",
        "lines_ds = files_ds.interleave(tf.data.TextLineDataset,cycle_length=3)\n",
        "\n",
        "for i, line in enumerate(lines_ds.take(9)):\n",
        "  if i%3 == 0:\n",
        "    print()\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\"\n",
            "b\"\\xef\\xbb\\xbfOf Peleus' son, Achilles, sing, O Muse,\"\n",
            "b'\\xef\\xbb\\xbfSing, O goddess, the anger of Achilles son of Peleus, that brought'\n",
            "\n",
            "b'His wrath pernicious, who ten thousand woes'\n",
            "b'The vengeance, deep and deadly; whence to Greece'\n",
            "b'countless ills upon the Achaeans. Many a brave soul did it send'\n",
            "\n",
            "b\"Caused to Achaia's host, sent many a soul\"\n",
            "b'Unnumbered ills arose; which many a soul'\n",
            "b'hurrying down to Hades, and many a hero did it yield a prey to dogs and'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a39W6MOdQRbV"
      },
      "source": [
        "#titanic data set\n",
        "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
        "titanic_lines = tf.data.TextLineDataset(titanic_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LuQsU04Q2b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8179df-f179-4513-af44-18be672fd499"
      },
      "source": [
        "for line in titanic_lines.take(10):\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone'\n",
            "b'0,male,22.0,1,0,7.25,Third,unknown,Southampton,n'\n",
            "b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n'\n",
            "b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y'\n",
            "b'1,female,35.0,1,0,53.1,First,C,Southampton,n'\n",
            "b'0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y'\n",
            "b'0,male,2.0,3,1,21.075,Third,unknown,Southampton,n'\n",
            "b'1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n'\n",
            "b'1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n'\n",
            "b'1,female,4.0,1,1,16.7,Third,G,Southampton,n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GIorUy0SGk0"
      },
      "source": [
        "def survived(line):\n",
        "  return tf.not_equal(tf.strings.substr(line,0,1),\"0\")\n",
        "survivors = titanic_lines.skip(1).filter(survived)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoIwhKOaSui5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3e0167-8116-4ffc-cd16-3303a6fffd23"
      },
      "source": [
        "for line in survivors.take(10):\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n'\n",
            "b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y'\n",
            "b'1,female,35.0,1,0,53.1,First,C,Southampton,n'\n",
            "b'1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n'\n",
            "b'1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n'\n",
            "b'1,female,4.0,1,1,16.7,Third,G,Southampton,n'\n",
            "b'1,male,28.0,0,0,13.0,Second,unknown,Southampton,y'\n",
            "b'1,female,28.0,0,0,7.225,Third,unknown,Cherbourg,y'\n",
            "b'1,male,28.0,0,0,35.5,First,A,Southampton,y'\n",
            "b'1,female,38.0,1,5,31.3875,Third,unknown,Southampton,n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMQio0u1TL80"
      },
      "source": [
        "Consuming CSV Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhpAk_wUTLnX"
      },
      "source": [
        "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8hC0SjYT5iF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "61313e61-c6a1-4918-fece-080b77a39f47"
      },
      "source": [
        "df = pd.read_csv(titanic_file, index_col=None)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  22.0  ...  unknown  Southampton      n\n",
              "1         1  female  38.0  ...        C    Cherbourg      n\n",
              "2         1  female  26.0  ...  unknown  Southampton      y\n",
              "3         1  female  35.0  ...        C  Southampton      n\n",
              "4         0    male  28.0  ...  unknown   Queenstown      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BqBRg0izkjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f5b0d6-24df-4c09-96a4-c642e30f0817"
      },
      "source": [
        "titanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))\n",
        "\n",
        "for feature_batch in titanic_slices.take(1):\n",
        "  for key,value in feature_batch.items():\n",
        "    print(\" {!r:20s}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 'survived'          : 0\n",
            " 'sex'               : b'male'\n",
            " 'age'               : 22.0\n",
            " 'n_siblings_spouses': 1\n",
            " 'parch'             : 0\n",
            " 'fare'              : 7.25\n",
            " 'class'             : b'Third'\n",
            " 'deck'              : b'unknown'\n",
            " 'embark_town'       : b'Southampton'\n",
            " 'alone'             : b'n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEJf6iBJ0rAr"
      },
      "source": [
        "titanic_batches = tf.data.experimental.make_csv_dataset(\n",
        "    titanic_file, batch_size = 4,\n",
        "    label_name=\"survived\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U1AHzoJ1DWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de800d3-038b-40fc-8c1e-3f6358b4c6eb"
      },
      "source": [
        "for feature_batch, label_batch in titanic_batches.take(1):\n",
        "  print(\"'survived' : {}\".format(label_batch))\n",
        "  print(\"features:\")\n",
        "  for key, value in feature_batch.items():\n",
        "    print(\" {!r:20s}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'survived' : [0 0 0 0]\n",
            "features:\n",
            " 'sex'               : [b'male' b'male' b'male' b'male']\n",
            " 'age'               : [34. 34. 46. 28.]\n",
            " 'n_siblings_spouses': [0 1 0 0]\n",
            " 'parch'             : [0 1 0 0]\n",
            " 'fare'              : [ 8.05 14.4  26.    8.05]\n",
            " 'class'             : [b'Third' b'Third' b'Second' b'Third']\n",
            " 'deck'              : [b'unknown' b'unknown' b'unknown' b'unknown']\n",
            " 'embark_town'       : [b'Southampton' b'Southampton' b'Southampton' b'Southampton']\n",
            " 'alone'             : [b'y' b'n' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUfmvykf3E5Q"
      },
      "source": [
        "titanic_batches = tf.data.experimental.make_csv_dataset(\n",
        "    titanic_file, batch_size=4,\n",
        "    label_name = \"survived\", select_columns=['class','fare','survived']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HdBRzjm4AOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7417d368-d708-42e4-a599-eb653def885e"
      },
      "source": [
        "for feature_batch, label_batch in titanic_batches.take(1):\n",
        "  print(\"'survived :' {}\".format(label_batch))\n",
        "  for key, value in feature_batch.items():\n",
        "    print(\" {!r:20s}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'survived :' [0 0 1 0]\n",
            " 'fare'              : [108.9    8.05  79.2   69.55]\n",
            " 'class'             : [b'First' b'Third' b'First' b'Third']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xexMdeO5RJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6c3b9d-2f30-4d96-927a-ec5181a03156"
      },
      "source": [
        "titanic_types = [tf.int32, tf.string, tf.float32, tf.int32, tf.int32, tf.float32, tf.string, tf.string, tf.string, tf.string]\n",
        "dataset = tf.data.experimental.CsvDataset(titanic_file, titanic_types, header=True)\n",
        "\n",
        "for line in dataset.take(10):\n",
        "  print([item.numpy() for item in line])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n",
            "[1, b'female', 38.0, 1, 0, 71.2833, b'First', b'C', b'Cherbourg', b'n']\n",
            "[1, b'female', 26.0, 0, 0, 7.925, b'Third', b'unknown', b'Southampton', b'y']\n",
            "[1, b'female', 35.0, 1, 0, 53.1, b'First', b'C', b'Southampton', b'n']\n",
            "[0, b'male', 28.0, 0, 0, 8.4583, b'Third', b'unknown', b'Queenstown', b'y']\n",
            "[0, b'male', 2.0, 3, 1, 21.075, b'Third', b'unknown', b'Southampton', b'n']\n",
            "[1, b'female', 27.0, 0, 2, 11.1333, b'Third', b'unknown', b'Southampton', b'n']\n",
            "[1, b'female', 14.0, 1, 0, 30.0708, b'Second', b'unknown', b'Cherbourg', b'n']\n",
            "[1, b'female', 4.0, 1, 1, 16.7, b'Third', b'G', b'Southampton', b'n']\n",
            "[0, b'male', 20.0, 0, 0, 8.05, b'Third', b'unknown', b'Southampton', b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsGpNgjvFnB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908ccbd2-647d-47bf-f4fc-65824e938e44"
      },
      "source": [
        "%%writefile missing.csv\n",
        "1,2,3,4\n",
        ",2,3,4\n",
        "1,,3,4\n",
        "1,2,,4\n",
        "1,2,3,\n",
        ",,,\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing missing.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J92vk-HF5Sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273e5089-a893-48ac-db3c-f1b406ed3830"
      },
      "source": [
        "#Creates a dataset that reads all of the records from two CSV files, each with\n",
        "#four float columns which have missing value.\n",
        "\n",
        "record_defaults = [999,999,999,999]\n",
        "dataset = tf.data.experimental.CsvDataset(\"missing.csv\", record_defaults)\n",
        "dataset = dataset.map(lambda*items: tf.stack(items))\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7efc196d26a8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'ValueError' object has no attribute 'lineno'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7efc196d26a8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'ValueError' object has no attribute 'lineno'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: (4,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR-ZrmjdHHmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3da746-843e-4508-97c2-884672906daf"
      },
      "source": [
        "for line in dataset:\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3 4]\n",
            "[999   2   3   4]\n",
            "[  1 999   3   4]\n",
            "[  1   2 999   4]\n",
            "[  1   2   3 999]\n",
            "[999 999 999 999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBBDvWFXHfRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a9e5f8-3866-4260-dcdb-4f7e160fcfee"
      },
      "source": [
        "# Creates a dataset that reads all of the record from two CSV files with\n",
        "# header, extracting float data from columns 2 and 4.\n",
        "record_defaults = [999,999] #Only provide defaults for the selected columns\n",
        "dataset = tf.data.experimental.CsvDataset(\"missing.csv\", record_defaults, select_cols=[1,3])\n",
        "dataset = dataset.map(lambda *items: tf.stack(items))\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: (2,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6VMOOOQI6uD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97e3781-5123-4002-d8d8-764d0f3778f5"
      },
      "source": [
        "for line in dataset:\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 4]\n",
            "[2 4]\n",
            "[999   4]\n",
            "[2 4]\n",
            "[  2 999]\n",
            "[999 999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWqLm9LCJw99"
      },
      "source": [
        "Consuming sets of files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAdwAMKyJwVy"
      },
      "source": [
        "flowers_root = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)\n",
        "flowers_root = pathlib.Path(flowers_root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cI6FyTLOLJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78a28b0-db81-4cd0-c189-7bfd7bbf0a37"
      },
      "source": [
        "for item in flowers_root.glob('*'):\n",
        "  print(item.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "daisy\n",
            "roses\n",
            "sunflowers\n",
            "dandelion\n",
            "tulips\n",
            "LICENSE.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wY9mdtPLMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9415ce4e-d3ec-493b-9904-4aae41d41d4d"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))\n",
        "\n",
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'/root/.keras/datasets/flower_photos/dandelion/5673112305_02fe19297b_n.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/sunflowers/184682320_73ccf74710.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/daisy/476856232_7c35952f40_n.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/dandelion/425800274_27dba84fac_n.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/dandelion/2596413098_7ef69b7e1d_m.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmZfJg54P22i"
      },
      "source": [
        "#Read the data using the tf.io.read_file function and extract the label from the\n",
        "#path, returing (image, label) pairs:\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = tf.strings.split(file_path, os.sep)[-2]\n",
        "  return tf.io.read_file(file_path), label\n",
        "\n",
        "labeled_ds = list_ds.map(process_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou2zk53uQ1gT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73da44cc-38c7-42ac-b5dd-7e6a92672d1f"
      },
      "source": [
        "for image_raw, label_text in labeled_ds.take(1):\n",
        "  print(repr(image_raw.numpy()[:100]))\n",
        "  print()\n",
        "  print(label_text.numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x03\\x02\\x02\\x03\\x02\\x02\\x03\\x03\\x03\\x03\\x04\\x03\\x03\\x04\\x05\\x08\\x05\\x05\\x04\\x04\\x05\\n\\x07\\x07\\x06\\x08\\x0c\\n\\x0c\\x0c\\x0b\\n\\x0b\\x0b\\r\\x0e\\x12\\x10\\r\\x0e\\x11\\x0e\\x0b\\x0b\\x10\\x16\\x10\\x11\\x13\\x14\\x15\\x15\\x15\\x0c\\x0f\\x17\\x18\\x16\\x14\\x18\\x12\\x14\\x15\\x14\\xff\\xdb\\x00C\\x01\\x03\\x04\\x04\\x05\\x04\\x05'\n",
            "\n",
            "b'roses'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}