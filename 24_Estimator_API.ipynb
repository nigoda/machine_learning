{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "24_Estimator_API.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/3rJp1Z9e9z0rosSmAOJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/24_Estimator_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rqcJ0vobydr"
      },
      "source": [
        "How to solve the Iris classification problem in TesorFlow using Estimators. An Estimator is tensorFlow's high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training.\n",
        "\n",
        "Note that in TensorFlow 2.0, the Keras API can accomplish many of these same tasks, and is believed to be an easier API to learn, If you are starting fresh, we would recommend you start with Keras. For more information about available high level APIs in TensorFlow 2.0, see Standardzing on Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbWgSlnd6bg"
      },
      "source": [
        "### **First things first**\n",
        "\n",
        "In order to get started, you will first import TensorFlow and a number of libraries you will need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4qRSU-Lbqab",
        "outputId": "a35fc1d7-23bf-4559-9d6b-bd674be1cbc7"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (57.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdT4rvFAe1cR"
      },
      "source": [
        "### **The data set**\n",
        "\n",
        "The sample program in the document builds and tests a model that classifies Iris flowers into three different species based on the size of their sepals and petals.\n",
        "\n",
        "You will train a model using the Iris data set. The Iris data set contains four feature and one label. The four feature identify the following botanical characteristics of individual Iris flower:\n",
        "\n",
        "*  sepal length\n",
        "*  sepal width\n",
        "*  petal length\n",
        "*  petal width\n",
        "\n",
        "Based on this information, you can define a few helpful constants for parsing the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib2eEbetgXUz"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIHZ9ZcThDxk"
      },
      "source": [
        "Next, download and parse the Iris data set using Keras and Pandas. Note that you keep distinct dataset for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Sh3g_xg_-J"
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\n",
        "  \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OVrw5LOiKL1"
      },
      "source": [
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6S8J7P1ipJn"
      },
      "source": [
        "You can inspect your data to see that you have float feature column and one int32 label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "WwX1mHVPizCE",
        "outputId": "a9c79280-fcc1-4f5c-b9e7-dbcd8d490be2"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09NMI3KWi22f"
      },
      "source": [
        "For each of the datasets, split out the labels, which the model will be trained to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFi6dSihi0cu"
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y  = test.pop('Species')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "6m01Y5UcjQU5",
        "outputId": "b07399c6-1140-4f61-d9cc-c4e685a42c59"
      },
      "source": [
        "# The label column has now been removed from the feature.\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QyGludbjsb7"
      },
      "source": [
        "### **Overview of programming with Estimators**\n",
        "\n",
        "Now that you have the data set up, you can define a model using a tensorFlow Estimator. An Estimator is any class derived from `tf.estimator.Estimator.` TensorFlow provides a collection of `tf.estimator (for example, LenearRegressor)` to impliment common ML algorithms. Beyond those,you may write your own custom Estimators. We recommend using pre-made Estimators when just getting started.\n",
        "\n",
        "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
        "\n",
        "*  Creatre one or more input functions.\n",
        "*  Define the model's fearture columns.\n",
        "*  Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
        "*  Call one or more methods on the Estimator object, pqassing the appropriate input function as the source of the data.\n",
        "\n",
        "let's see how those tasks are implemented for Iris classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK3tVJdnl_NN"
      },
      "source": [
        "### **Create input function**\n",
        "\n",
        "You must create input function that return a `tf.data.Dataset` object which outputs the following two-element tuple:\n",
        "*  features - A Python dictionary in which:\n",
        "      *  Each key is the name of a feature.\n",
        "      *  Each values is an array containing all of that feature's values.\n",
        "\n",
        "*  label - An array containing the values of the label for every example.\n",
        "\n",
        "Just to demonstrate the format of the input function, here's a simple implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAc1Rd59jnHv"
      },
      "source": [
        "def input_evaluation_set():\n",
        "  features = {'SepalLength' : np.array([6.4, 5.0]),\n",
        "              'SepalWidth' : np.array([2.8, 2.3]),\n",
        "              'PetalLength' : np.array([5.6, 3.3]),\n",
        "              'PetalWidth' : np.array([2.2, 1.0])}\n",
        "  labels = np.array([2, 1])\n",
        "  return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQULcuv1orD5"
      },
      "source": [
        "Your input function may generate the featurea dictionary and label list any way you like. However, we recommend using TensorFlow's Dataset API, which can parse all sorts of data.\n",
        "\n",
        "The Dataset API can handle a lot of common cases for you. For example, using Dataset API, you can easily read in records from a large coollection of files in parallel and join them into a single stream.\n",
        "\n",
        "To keep things simple in this example you are going to load the data with pandas, and build an input pipeline from this in-memory data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGjlOfuijXpR"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "  \"\"\"An input funtion for training or evaluation\"\"\"\n",
        "  # Convert the inputs to a Dataset.\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "  # Shuffle and repeat if you are in training mode.\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "  return dataset.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bXm-5KkrBhU"
      },
      "source": [
        "### **Define the feature columns**\n",
        "\n",
        "A feature column is an object describing how the modle should use raw data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The `tf.feature_column` module provides many options for representing data to the model.\n",
        "\n",
        "For Iris, The 4 raw features are numeric values, so we'll build a list of feature columns to tell the Estimator model to represent each of the four features are 32-bit floating-point values. Therefore, the code to create the feature column is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz86jHVzqw7W"
      },
      "source": [
        "# Feature columns describe how to use the input.\n",
        "my_feature_columns =[]\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYipxY5ttHcv"
      },
      "source": [
        "Feature columns can be far more sophisticated than those we're showing here. Now that you have the description of how you want the model to represent the raw features, you can build the estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZpgkVU3twgq"
      },
      "source": [
        "### Instantiate an estimator\n",
        "\n",
        "The Iris problem is a classic classification problem. Fortunately, TensorFlow provides several pre-made classifier Estimators, including:\n",
        "\n",
        "*  `tf.estimator.DNNClassifier` for deep models that perform multi-class classifiaction.\n",
        "*  `tf.estimator.DNNLinearCombinedClassification` for wide & deep models.\n",
        "*  `tf.estimator.LinearClassifier` for classification based on linear models.\n",
        "\n",
        "For the Iris problem, `tf.estimator.DNNClassifier` seems like the best choice. Here's how you instantiated this Estimator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ybJoT0tBA6",
        "outputId": "98f6f499-67ce-44d7-af71-c9c024ca422c"
      },
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 10 nodes each.\n",
        "    hidden_units=[30, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfm3lb8wl\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfm3lb8wl', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh-SFjI1wT0l"
      },
      "source": [
        "### **Train, Evaluate, and Preedict**\n",
        "\n",
        "Now that you have an Estimator object, you can call methods to do the folowing:\n",
        "\n",
        "*  Train the model.\n",
        "*  Evaluate the trained model.\n",
        "*  Use the trained model to make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwnI8G7lwyWq"
      },
      "source": [
        "**Train the model**\n",
        "\n",
        "Train the model by calling the estimator's train method as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AddX_CBWw99o",
        "outputId": "a308fe09-3035-48da-ebdb-01ff9f271ea9"
      },
      "source": [
        "# Train the Model.\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps = 5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpfm3lb8wl/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 4.9171724, step = 0\n",
            "INFO:tensorflow:global_step/sec: 407.798\n",
            "INFO:tensorflow:loss = 2.5517285, step = 100 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.358\n",
            "INFO:tensorflow:loss = 1.927783, step = 200 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.052\n",
            "INFO:tensorflow:loss = 1.5905243, step = 300 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.666\n",
            "INFO:tensorflow:loss = 1.3668315, step = 400 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.414\n",
            "INFO:tensorflow:loss = 1.1677252, step = 500 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.207\n",
            "INFO:tensorflow:loss = 1.0947621, step = 600 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.258\n",
            "INFO:tensorflow:loss = 0.9998762, step = 700 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.281\n",
            "INFO:tensorflow:loss = 0.93540597, step = 800 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.84\n",
            "INFO:tensorflow:loss = 0.89184415, step = 900 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.932\n",
            "INFO:tensorflow:loss = 0.84730434, step = 1000 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.399\n",
            "INFO:tensorflow:loss = 0.8192316, step = 1100 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.257\n",
            "INFO:tensorflow:loss = 0.78997594, step = 1200 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.311\n",
            "INFO:tensorflow:loss = 0.7643462, step = 1300 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.066\n",
            "INFO:tensorflow:loss = 0.74349606, step = 1400 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.626\n",
            "INFO:tensorflow:loss = 0.72658896, step = 1500 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 438.401\n",
            "INFO:tensorflow:loss = 0.70311475, step = 1600 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.216\n",
            "INFO:tensorflow:loss = 0.69456196, step = 1700 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.828\n",
            "INFO:tensorflow:loss = 0.68107617, step = 1800 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.573\n",
            "INFO:tensorflow:loss = 0.68137735, step = 1900 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.719\n",
            "INFO:tensorflow:loss = 0.6604438, step = 2000 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.567\n",
            "INFO:tensorflow:loss = 0.6523197, step = 2100 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.818\n",
            "INFO:tensorflow:loss = 0.6391918, step = 2200 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.655\n",
            "INFO:tensorflow:loss = 0.63390386, step = 2300 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.189\n",
            "INFO:tensorflow:loss = 0.6194265, step = 2400 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.428\n",
            "INFO:tensorflow:loss = 0.6135606, step = 2500 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.386\n",
            "INFO:tensorflow:loss = 0.6091587, step = 2600 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.982\n",
            "INFO:tensorflow:loss = 0.5926273, step = 2700 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.187\n",
            "INFO:tensorflow:loss = 0.61208194, step = 2800 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.595\n",
            "INFO:tensorflow:loss = 0.5795321, step = 2900 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.704\n",
            "INFO:tensorflow:loss = 0.578082, step = 3000 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.848\n",
            "INFO:tensorflow:loss = 0.5660771, step = 3100 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.191\n",
            "INFO:tensorflow:loss = 0.5690845, step = 3200 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.215\n",
            "INFO:tensorflow:loss = 0.5616983, step = 3300 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.263\n",
            "INFO:tensorflow:loss = 0.5418822, step = 3400 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.293\n",
            "INFO:tensorflow:loss = 0.53326523, step = 3500 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.855\n",
            "INFO:tensorflow:loss = 0.5386485, step = 3600 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.445\n",
            "INFO:tensorflow:loss = 0.55179155, step = 3700 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.438\n",
            "INFO:tensorflow:loss = 0.5342045, step = 3800 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.283\n",
            "INFO:tensorflow:loss = 0.5285669, step = 3900 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.204\n",
            "INFO:tensorflow:loss = 0.52965444, step = 4000 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.505\n",
            "INFO:tensorflow:loss = 0.5235408, step = 4100 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.272\n",
            "INFO:tensorflow:loss = 0.518528, step = 4200 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.231\n",
            "INFO:tensorflow:loss = 0.5151945, step = 4300 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.642\n",
            "INFO:tensorflow:loss = 0.5019592, step = 4400 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.725\n",
            "INFO:tensorflow:loss = 0.5114334, step = 4500 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.272\n",
            "INFO:tensorflow:loss = 0.49853638, step = 4600 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.533\n",
            "INFO:tensorflow:loss = 0.49987543, step = 4700 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.472\n",
            "INFO:tensorflow:loss = 0.49537548, step = 4800 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.932\n",
            "INFO:tensorflow:loss = 0.5039351, step = 4900 (0.199 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpfm3lb8wl/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.4839715.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fbef9b2f750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iHZOr6pyCUq"
      },
      "source": [
        "Note that you wrap up your input_fn call in a lambda to capture the arguments while providing an input function that takes no arguments, as expected by the Estimator. The steps argument tells tthe methods to stop training after a number of training steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWf1dHiyy6S6"
      },
      "source": [
        "**Evaluate the trained model**\n",
        "\n",
        "Now that the model has been trained, you can get some statistics on its performance. The following code blocks evaluates the accuracy of the trained model on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsNL08mRxOjW",
        "outputId": "1292c197-0c7f-4af7-9270-fb10a167f0fd"
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-30T12:39:16\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpfm3lb8wl/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.24682s\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-30-12:39:16\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7, average_loss = 0.57767546, global_step = 5000, loss = 0.57767546\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpfm3lb8wl/model.ckpt-5000\n",
            "\n",
            "Test set accuracy: 0.700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3AXqWII0Nww"
      },
      "source": [
        "Unlike the call to train method, you did not pass the steps argumnet to evaluate. The `input_fn` for eval only yields a single epoch of data. The `eval_result` dictionary also contains the `average_loss(mean loss per samples), the loss(mean loss per mini-batch)` and the value of the estimator's `global_step(the number of training iterations it underwent).` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugwZQ--11hOF"
      },
      "source": [
        "**Making predication(inferring) from the training model**\n",
        "\n",
        "You now have a trained model that produces good evaluation results. You can now use the trained model to predict the speies of an Iris flowers based on some unlabeled measurements. As with training and evaluation, you make predictions using a single function call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlUCGQno0CTi"
      },
      "source": [
        "# Generate predictions from the model\n",
        "expected = ['Setosa', 'Versicolor', 'virginica']\n",
        "predict_x = {\n",
        "    'SepalLength' : [5.1, 5.9, 6.9],\n",
        "    'SepalWidth' : [3.3, 3.0, 3.1],\n",
        "    'PetalLength' : [1.7, 4.2, 5.4],\n",
        "    'PetalWidth' : [0.5, 1.5, 2.1],\n",
        "}\n",
        "\n",
        "def input_fn(features, batch_size=256):\n",
        "  \"\"\"An input function for prediction.\"\"\"\n",
        "  # Convert the input to a Dataset without labels.\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predictions = classifier.predict(\n",
        "    input_fn=lambda: input_fn(predict_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9gz_OZ33mf5"
      },
      "source": [
        "The predict method returna a python iterable, yielding a dictionary of prediction results for each examples. The following code prints a few predictions and their probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5r_ImDI3jTn",
        "outputId": "f96ba8d0-0295-4bae-ca57-078792214833"
      },
      "source": [
        "for pred_dict, expec in zip(predictions, expected):\n",
        "  class_id = pred_dict['class_ids'][0]\n",
        "  probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "  print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
        "      SPECIES[class_id], 100*probability, expec))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpfm3lb8wl/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (76.1%), expected \"Setosa\"\n",
            "Prediction is \"Virginica\" (46.8%), expected \"Versicolor\"\n",
            "Prediction is \"Virginica\" (58.6%), expected \"virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}