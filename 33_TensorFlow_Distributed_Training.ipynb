{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "33_TensorFlow_Distributed_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP38gbK5l/cLeCUcfdw41Ag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f8480c7167e447a8c007edadf8e30f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38535b86b5a44e78a2debf271c0cceb7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c926a02660984a45a2750953afd1fa9c",
              "IPY_MODEL_431f451428074375af39b8c77127e5fe"
            ]
          }
        },
        "38535b86b5a44e78a2debf271c0cceb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c926a02660984a45a2750953afd1fa9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bcc0464554fa469786ec180c98503128",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b16a5f5cbd8d4489b4c91543b9d6ea30"
          }
        },
        "431f451428074375af39b8c77127e5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb9704202e374f01a169f4ba9476a755",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:06&lt;00:00,  1.56s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b941c854343140efb3b3ebc0a22b80bb"
          }
        },
        "bcc0464554fa469786ec180c98503128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b16a5f5cbd8d4489b4c91543b9d6ea30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb9704202e374f01a169f4ba9476a755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b941c854343140efb3b3ebc0a22b80bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/33_TensorFlow_Distributed_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAvCkpWJlV5n"
      },
      "source": [
        "## **Type of strategies**\n",
        "\n",
        "https://www.tensorflow.org/guide/distributed_training\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#scrollTo=Z2XI9Zp9ohCJ\n",
        "\n",
        "`tf.distribute.Strategy` intends to cover a number of use cases along different axes. Some of these combinations are currently supported and others will be added in the future. Some of these are:\n",
        "\n",
        "*  Synchronous vs asynchronous training: These are two common ways of distributing training with data parallelism. In sync training, all workers train over different silces of input data in sync, and aggregating gradients at each step. In async training, all workers are independently training over the input data and updating variables asynchronously. Typically sync training is supported via all-reduce and async through parameter server architecture.\n",
        "\n",
        "*  Hardware platform: Users may want to scale their training onto multiple GPUs on one machine, or multiple machines in a network (with 0 or more GPUs each), or on Cloud TPUs.\n",
        "\n",
        "In order to support these use cases, there are 6 strategies available.\n",
        "\n",
        "| Training API          \t| MirroredStrategy  \t| TPUStrategy         \t| MultiWorkerMirroredStrategy     \t| CentralStorageStrategy          \t| ParameterServerStrategy  \t|\n",
        "|:-----------------------\t|:-------------------\t|:---------------------\t|:---------------------------------\t|:---------------------------------\t|:--------------------------\t|\n",
        "| **Keras API**             \t| Supported         \t|  Supported \t| Supported \t| Experimental support \t| Supported planned post 2.4 \t|\n",
        "| **Custom training loop**  \t| Supported \t| Supported   \t| Supported            \t| Experimental support           \t| Experimental support         \t|\n",
        "| **Estimator API**         \t| Limited Support         \t| Not supported           \t| Limited Support                       \t| Limited Support                       \t| Limited Support                \t|\n",
        "\n",
        "Note: [Experimental support](https://www.tensorflow.org/guide/versions#what_is_not_covered) means the APIs are not covered by any compatibilities guarantees.\n",
        "\n",
        "Note: Estimator support is limited. Basic training and evaluation are experimental, and advanced features—such as scaffold—are not implemented. You should be using Keras or custom training loops if a use case is not covered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziOvHSxaovDC"
      },
      "source": [
        "## **Overview**\n",
        "The `tf.distribute.Strategy` API provides an abstraction for distributing your training across multiple processing units. The goal is to allow user to enable distributed training using existing models and training code, with minimal changes.\n",
        "\n",
        "This uses the `tf.distribute.MirroredStrategy`, which does in-graph replication with synchronous training on many GPUs on one machine. Essentially, it copies all of the model's variables to each processor. Then, it uses all-reduce to combine the gradients from all processor and applies the combined values to all copies of the model.\n",
        "\n",
        "`MirroredStategy` is one of several distribution strategy available in TensorFow core. You can read about more strategies at distribution strategy guide.\n",
        "\n",
        "### **Keras API**\n",
        "This example uses the tf.keras API to build the model and training loops, see the tf.distribute Strategy with training loops \n",
        "\n",
        "## **Import dependencies**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7em4LMArk8sA"
      },
      "source": [
        "# Import TensorFlow and TensorFlow Datasets\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8bJt9kDnNTc",
        "outputId": "04e62506-d344-4d96-e4fb-de8d2aabf062"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQf-gOS85O-c"
      },
      "source": [
        "## **Download the dataset**\n",
        "Download the MNIST dataset and load it from TensorFlow Datasets. This return a dataset in `tf.data` format.\n",
        "\n",
        "Setting `with_info` to `True` includes the metadata for the entire dataset, which is being saved here to info. Among other things, this metadata object includes the number of train ans test examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "8f8480c7167e447a8c007edadf8e30f7",
            "38535b86b5a44e78a2debf271c0cceb7",
            "c926a02660984a45a2750953afd1fa9c",
            "431f451428074375af39b8c77127e5fe",
            "bcc0464554fa469786ec180c98503128",
            "b16a5f5cbd8d4489b4c91543b9d6ea30",
            "bb9704202e374f01a169f4ba9476a755",
            "b941c854343140efb3b3ebc0a22b80bb"
          ]
        },
        "id": "Y2lHvkpu5MSN",
        "outputId": "aa2750cd-ad0c-40bb-90b5-d023caab9812"
      },
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f8480c7167e447a8c007edadf8e30f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF331Da86cGZ"
      },
      "source": [
        "## **Define distibution strategy**\n",
        "Create a `MirroredStrategy` object. This will handle distribution, and provides a context manager (`tf.distribute.MirroredStrategy.scope`) to build the model inside.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs8WBZzw5HjX",
        "outputId": "243a2e5a-26cc-4893-ba09-95ccdc34ce6c"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSugkWhT7JNI",
        "outputId": "3ee08574-8ccb-44a8-c177-803753164011"
      },
      "source": [
        "print('Number of device: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of device: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBGn7qzG7Zne"
      },
      "source": [
        "## **Setup input pipeline**\n",
        "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlQw6BJv7WmI"
      },
      "source": [
        "# You can also do info.splits.total_num_examples to get the total\n",
        "# number of examples in the dataset.\n",
        "\n",
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FYvpesT9F7r"
      },
      "source": [
        "Pixel values, which are 0-255 have to be normalized to the 0-1 range. Define this scale in a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJSL6ZOA9DXB"
      },
      "source": [
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5ovAgUd9sio"
      },
      "source": [
        "Apply this function to the training and test data, shuffle the training data, and batch it for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwP6x9vh98wY"
      },
      "source": [
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r46rS9e7-Z3m"
      },
      "source": [
        "## **Create the model**\n",
        "Create and compile the Keras model in the context of strategy.scope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk_phF2F9rvE",
        "outputId": "ace1c49c-f904-42d0-d3c0-581437caf49a"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Rl86BD_mvD"
      },
      "source": [
        "## **Define the callbacks**\n",
        "The callbacks used here are:\n",
        "*  *TensorBoard*: This callback writes a log for TensorBoard which allows you to visualize the graphs.\n",
        "*  *Model Checckpoint*: This callback saves the model after every epoch.\n",
        "* *Learning Rate Scheduler:* Using this callback, you can schedule the learning rate to change after every epoch/batch.\n",
        "\n",
        "For illustrative purposes, add a print callback to display the *learning rate* in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwFkc8jH_efc"
      },
      "source": [
        "# Define the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b80lSgJoB7lb"
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "  if epoch < 3:\n",
        "    return 1e-3\n",
        "  elif epoch >=3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VUhHpX_XqVp"
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYkc6-QiYMs3"
      },
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi1P2fIsaZAL"
      },
      "source": [
        "## **Train and evaluate**\n",
        "Now, train the model in the usual way calling fit on the model and passing in the dataset created at the begining of the tutorial. This step is the same whether you are distributing the training or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqtvXt_laAwv",
        "outputId": "68c7966e-55a7-4a0f-b374-ed72bd1d131c"
      },
      "source": [
        "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  3/938 [..............................] - ETA: 5:58 - loss: 2.2532 - accuracy: 0.1406WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_begin` time: 0.0825s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_begin` time: 0.0825s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0434s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0434s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 43s 10ms/step - loss: 0.2204 - accuracy: 0.9359\n",
            "\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "Epoch 2/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0723 - accuracy: 0.9784\n",
            "\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "Epoch 3/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0491 - accuracy: 0.9849\n",
            "\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "Epoch 4/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0278 - accuracy: 0.9926\n",
            "\n",
            "Learning rate for epoch 4 is 9.999999747378752e-05\n",
            "Epoch 5/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0247 - accuracy: 0.9937\n",
            "\n",
            "Learning rate for epoch 5 is 9.999999747378752e-05\n",
            "Epoch 6/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0229 - accuracy: 0.9941\n",
            "\n",
            "Learning rate for epoch 6 is 9.999999747378752e-05\n",
            "Epoch 7/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0214 - accuracy: 0.9944\n",
            "\n",
            "Learning rate for epoch 7 is 9.999999747378752e-05\n",
            "Epoch 8/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0187 - accuracy: 0.9955\n",
            "\n",
            "Learning rate for epoch 8 is 9.999999747378752e-06\n",
            "Epoch 9/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0184 - accuracy: 0.9955\n",
            "\n",
            "Learning rate for epoch 9 is 9.999999747378752e-06\n",
            "Epoch 10/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0182 - accuracy: 0.9956\n",
            "\n",
            "Learning rate for epoch 10 is 9.999999747378752e-06\n",
            "Epoch 11/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0180 - accuracy: 0.9958\n",
            "\n",
            "Learning rate for epoch 11 is 9.999999747378752e-06\n",
            "Epoch 12/12\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0179 - accuracy: 0.9958\n",
            "\n",
            "Learning rate for epoch 12 is 9.999999747378752e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49204577d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFlrpByzdURa"
      },
      "source": [
        "As you can see below, the checkpoint are getting saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SRl4XCddo9K",
        "outputId": "803edb0e-b2a3-43cc-f7e7-7d04f5a90d5a"
      },
      "source": [
        "# check the checkpoint directory\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt_4.data-00000-of-00001\n",
            "ckpt_10.data-00000-of-00001  ckpt_4.index\n",
            "ckpt_10.index\t\t     ckpt_5.data-00000-of-00001\n",
            "ckpt_11.data-00000-of-00001  ckpt_5.index\n",
            "ckpt_11.index\t\t     ckpt_6.data-00000-of-00001\n",
            "ckpt_12.data-00000-of-00001  ckpt_6.index\n",
            "ckpt_12.index\t\t     ckpt_7.data-00000-of-00001\n",
            "ckpt_1.data-00000-of-00001   ckpt_7.index\n",
            "ckpt_1.index\t\t     ckpt_8.data-00000-of-00001\n",
            "ckpt_2.data-00000-of-00001   ckpt_8.index\n",
            "ckpt_2.index\t\t     ckpt_9.data-00000-of-00001\n",
            "ckpt_3.data-00000-of-00001   ckpt_9.index\n",
            "ckpt_3.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLZ62xNqd5rH"
      },
      "source": [
        "To see how the model perform, load the latest checkpoint and call *evaluate* on the test data.\n",
        "\n",
        "Call *evaluate* as before using appropriate datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AymXi6OjdxY5",
        "outputId": "620d9a92-9779-41cd-9fd9-dd8e499a55ba"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 9ms/step - loss: 0.0398 - accuracy: 0.9862\n",
            "Eval loss: 0.03980964422225952, Eval Accuracy: 0.9861999750137329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gVxsT51fP72"
      },
      "source": [
        "To see the output, you can download and view the TensorBoard logs at the terminal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy2CJxoKg6cz"
      },
      "source": [
        "__$ tensorboard --logdir=path/to/log-directory__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPAzHVRBfsJp",
        "outputId": "638e4560-3127-452a-fdb0-0984578a0d89"
      },
      "source": [
        "!ls -sh ./logs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.0K\n",
            "4.0K train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP01kJkSgVvx"
      },
      "source": [
        "## **Export to SavedModel**\n",
        "Export the graph and the variables to the platform-agnostic SaveModel format. After your model is saved, you can load it with or without the scope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60ZfrEljf0yH"
      },
      "source": [
        "path = 'saved_model/'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1O6Flj4hoqs",
        "outputId": "0e3472c6-4679-4331-cebf-dc12017fb40d"
      },
      "source": [
        "model.save(path, save_format='tf')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osDFwZaPlJjd"
      },
      "source": [
        "load the model without `strategy.scope.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0XIVUKkhx_I",
        "outputId": "723f7511-a29c-45f0-c9b1-fdf1dfb4ba52"
      },
      "source": [
        "unreplicated_model = tf.keras.models.load_model(path)\n",
        "\n",
        "unreplicated_model.compile(\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  1/157 [..............................] - ETA: 32s - loss: 0.0985 - accuracy: 0.9688"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0398 - accuracy: 0.9862\n",
            "Eval loss: 0.03980964422225952, Eval Accuracy: 0.9861999750137329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y_zS5lL2YJM"
      },
      "source": [
        "Load the model with `strategy.scope.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Htsiv78lYbK",
        "outputId": "c2f8f259-c156-4ee6-be91-6bb56bb35b2c"
      },
      "source": [
        "with strategy.scope():\n",
        "  replicated_model = tf.keras.models.load_model(path)\n",
        "  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "  \n",
        "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
        "  print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 4ms/step - loss: 0.0398 - accuracy: 0.9862\n",
            "Eval loss: 0.03980964422225952, Eval Accuracy: 0.9861999750137329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czmQSn1y356h"
      },
      "source": [
        "### Examples and Tutorials\n",
        "Here are some examples for using distribution strategy with keras fit/compile:\n",
        "1. [Transformer](https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer_main.py) example trained using `tf.distribute.MirroredStrategy`\n",
        "2. [NCF](https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py) example trained using `tf.distribute.MirroredStrategy`.\n",
        "\n",
        "More examples listed in the [Distribution strategy guide](../../guide/distributed_training.ipynb#examples_and_tutorials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBqTJ1Y339MU"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "* Read the [distribution strategy guide](../../guide/distributed_training.ipynb).\n",
        "* Read the [Distributed Training with Custom Training Loops](custom_training.ipynb) tutorial.\n",
        "* Visit the [Performance section](../../guide/function.ipynb) in the guide to learn more about other strategies and [tools](../../guide/profiler.md) you can use to optimize the performance of your TensorFlow models.\n",
        "\n",
        "Note: `tf.distribute.Strategy` is actively under development and we will be adding more examples and tutorials in the near future. Please give it a try. We welcome your feedback via [issues on GitHub](https://github.com/tensorflow/tensorflow/issues/new)."
      ]
    }
  ]
}