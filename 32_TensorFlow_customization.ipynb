{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "32_TensorFlow_customization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKEyj0/OlKB4NbCI4Y0r9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/32_TensorFlow_customization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuPxwF0XrR3l"
      },
      "source": [
        "# **TensorFlow Customization**\n",
        "\n",
        "https://www.tensorflow.org/guide/basic_training_loops\n",
        "\n",
        "So far in this, we used methods provided by build in TF APIs like tf.keras and tf.Estimator. While these constructs are sufficient to start any AI project, there could be situations where you may have to implement custom models, loss function or metrics. Tensorflow 2.0 provides support for extending its functionality. In this, we will learn how to customize TF 2.0 functionality.\n",
        "\n",
        "This is an introductory TensorFlow that shows how to:\n",
        "*  Import the required package\n",
        "*  Create and use tensors\n",
        "*  Use GPU acceleration\n",
        "*  Demonstrate `tf.data.Dataset`\n",
        "\n",
        "## **Import TensorFlow**\n",
        "To get started, import the `tensorflow` module. As of TensorFlow 2, eager execution is turned on by default. This enables a more interactive fronted to Tesorflow, the details of which we will discuss much later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da-zZYNepuX8"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdiK5Tv_rIGI"
      },
      "source": [
        "## **Tensor**\n",
        "A Tensor is a multi-dimensional array. Similar to NumPy `ndarray` objects, `tf.tensor` objects have a data type and a shape. Additionally, `tf.Tensor`s can reside in accelerator memory (like a GPU). TensorFlow offers a rich library of operations ([tf.add ](https://www.tensorflow.org/api_docs/python/tf/math/add), [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul), [tf.linalg.inv](https://www.tensorflow.org/api_docs/python/tf/linalg/inv) etc.) that consume and produce `tf.Tensor`s. These operations automatically convert native Python types, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rrSt3C8vSKB",
        "outputId": "af6d6c0a-b469-4029-a395-ba8acc472a09"
      },
      "source": [
        "print(tf.add(1, 2))\n",
        "print(tf.add([1, 2], [3, 4]))\n",
        "print(tf.square(5))\n",
        "print(tf.reduce_sum([1, 2, 3]))\n",
        "\n",
        "# Operatior overloading is also supported\n",
        "print(tf.square(2) + tf.square(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
            "tf.Tensor(25, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeQNIlhewCr0"
      },
      "source": [
        "Each `tf.Tensor` has a shape and a datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-QNWKTTv9nk",
        "outputId": "11581413-fc59-41c1-ef2f-208c928dc0c8"
      },
      "source": [
        "x = tf.matmul([[1]], [[2, 3]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
            "(1, 2)\n",
            "<dtype: 'int32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWdlr0uqwopX"
      },
      "source": [
        "The most obvious different between NumPy array and `tf.Tensor`s are:\n",
        "1. Tensors can be backed by accelerator memory(like GPU, TPU).\n",
        "2.  Tensors are immutable.\n",
        "\n",
        "## NumPy Compatibility\n",
        "Converting between a TensorFlow [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor)s and a Numpy `ndarray` is easy:\n",
        "\n",
        "*  TensorFlow operations automatically convert NumPy ndarray to Tensors.\n",
        "*  NumPy operations automatically convert Tensors to NumPy ndarrays.\n",
        "\n",
        "Tensors are expilcitly convert to NumPy ndarrays using their `.numpy` method. These conversions are typically cheap since the array and `tf.tensor` share the underlying memory representation, if possible. However, sharing the underlying representation isn't always possible since the `tf.Tensor` may be hosted in GPU memory while NumPy arrays are always backed by host memory, and the conversion involves a copy from GPU TO host memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s8L5DbGwhW5",
        "outputId": "a53f3336-b1e9-4bfd-c394-77067ab86496"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "ndarray = np.ones([3, 3])\n",
        "\n",
        "print(\"TensorFlow operations convert numpy arrays to tensors automatically\")\n",
        "tensor = tf.multiply(ndarray, 42)\n",
        "print(tensor)\n",
        "\n",
        "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
        "print(np.add(tensor, 1))\n",
        "\n",
        "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
        "print(tensor.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow operations convert numpy arrays to tensors automatically\n",
            "tf.Tensor(\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
            "And NumPy operations convert Tensors to numpy arrays automatically\n",
            "[[43. 43. 43.]\n",
            " [43. 43. 43.]\n",
            " [43. 43. 43.]]\n",
            "The .numpy() method explicitly converts a Tensor to a numpy array\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTyPVHuC1F-F"
      },
      "source": [
        "# **GPU acceleration**\n",
        "\n",
        "Many TensorFlow operations are accelerated using the GPU for computation. Without any annotations, TensorFlow automatically decides whether to use the GPU or CPU for an operation-copying the tensor between CPU and GPU memory, if necessary. Tensors produces by an operation are typically backed by the memory of the device on which the operation executed, for example:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq9rJa6e00lM",
        "outputId": "ae14abd4-0588-4dec-9da6-8328338035e8"
      },
      "source": [
        "x = tf.random.uniform([3, 3])\n",
        "\n",
        "print(\"Is there a GPU available: \")\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "print(\"Is the Tensor on GPU #0: \")\n",
        "print(x.device.endswith('GPU:0'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is there a GPU available: \n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Is the Tensor on GPU #0: \n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiDspg6I27so"
      },
      "source": [
        "## Device Name\n",
        "\n",
        "The `Tensor.device` property provides a fully qualified string name of the device hosting the contents of the tensor. This name encodes many details, such as an identifier of the network address of the host on which this program is executing and the device with that host. This is required for distributed execution of a TensorFlow program. The string endsnwith `GPU:<N>` if the tensor is placed on the `N`-th GPU on the host.\n",
        "\n",
        "## Explicit Deice Placement\n",
        "In TensorFlow, *placement* refers to how individual operations are assigned (placed on) a device for execution. As mentioned, when there is no explicit guidance provided, TensorFlow automatically decides which device to execute an operation and copies tensors to specific devices using the `tf.device` context manager, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHIvx5Dj2kB2",
        "outputId": "b2be3d04-fdef-4c9a-dee4-732dc6279a29"
      },
      "source": [
        "import time\n",
        "\n",
        "def time_matmul(x):\n",
        "  start = time.time()\n",
        "  for loop in range(10):\n",
        "    tf.matmul(x, x)\n",
        "\n",
        "  result = time.time()-start\n",
        "\n",
        "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "# Force execution on CPU\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "  x = tf.random.uniform([1000, 1000])\n",
        "  assert x.device.endswith(\"CPU:0\")\n",
        "  time_matmul(x)\n",
        "\n",
        "# Force execution on GPU #0 if available\n",
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"On GPU:\")\n",
        "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU2 for the 3rd etc.\n",
        "    x = tf.random.uniform([1000, 1000])\n",
        "    assert x.device.endswith(\"GPU:0\")\n",
        "    time_matmul(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On CPU:\n",
            "10 loops: 322.93ms\n",
            "On GPU:\n",
            "10 loops: 555.51ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIuaOLVf7rYa"
      },
      "source": [
        "## Datasets\n",
        "This section uses the `tf.data.Dataset API` to build a pipeline for feeding data to your model. The `[tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)` API is used to build performant, complex input pipeline from simple, reusable pieces that will feed your model's training or evaluation loops.\n",
        "\n",
        "## Create a sourse **Dataset**\n",
        "Create a *source* dataset  using one of the factory functions like `Dataset.from_tensors, Dataset.from_tensor_slices`, or using objects that read from files like `TextLineDataset` or `TFRecordDataset`. See the *TensorFlow Dataset guide* for more information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N05Jw2E369PC"
      },
      "source": [
        "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Create a CSV file\n",
        "import tempfile\n",
        "_, filename = tempfile.mkstemp()\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "  f.write(\"\"\"Line 1\n",
        "  Line 2\n",
        "  Line 3\n",
        "    \"\"\")\n",
        "  \n",
        "ds_file = tf.data.TextLineDataset(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG58oftuAfm8"
      },
      "source": [
        "## Apply transformations\n",
        "Use the transformation functions like `map`, `batch`, and 'shuffle' to apply transformations to dataset records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E275DpbsAaux"
      },
      "source": [
        "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
        "\n",
        "ds_file = ds_file.batch(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DBJeIs4BVBX"
      },
      "source": [
        "## Iterate\n",
        "`tf.data.Dataset` objects support iteration to loop over record:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VuBflC4A0WP",
        "outputId": "7be352b5-4485-4379-e33f-42c17684e17f"
      },
      "source": [
        "print('Elements of ds_tensor:')\n",
        "for x in ds_tensors:\n",
        "  print(x)\n",
        "\n",
        "print('\\nElement in ds_file:')\n",
        "for x in ds_file:\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elements of ds_tensor:\n",
            "tf.Tensor([1 9], shape=(2,), dtype=int32)\n",
            "tf.Tensor([16  4], shape=(2,), dtype=int32)\n",
            "tf.Tensor([36 25], shape=(2,), dtype=int32)\n",
            "\n",
            "Element in ds_file:\n",
            "tf.Tensor([b'Line 1' b'  Line 2'], shape=(2,), dtype=string)\n",
            "tf.Tensor([b'  Line 3' b'    '], shape=(2,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZRayaJKMfXu"
      },
      "source": [
        "Customization opportunities:\n",
        "*  Model\n",
        "*  Loss function\n",
        "*  Training Loop\n",
        "*  Metrics\n",
        "\n",
        "Let's learn how we can carry out this customizations. \n",
        "\n",
        "## **Writing custom layers**\n",
        "Layers provide higher level of abstraction for implementing ML models. Many machine learning models are expressible as the composition and stacking of relatively simple layers, and TensorFlow provides both a set of many common layers as a well as easy ways for you to write your own application-specific layers either from  scratch or as the composition of existing layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5l0z04sO7Yo"
      },
      "source": [
        "# In the tf.keras.layers package, layers are objects. To construct a layer,\n",
        "# simply construct the object. Most layers take as a first argument the number\n",
        "# of output dimensions / channels.\n",
        "layer = tf.keras.layers.Dense(100)\n",
        "\n",
        "# The number of input dimensions is often unncessary, as it can be inferred\n",
        "# the first time the layer is used, but it can be provided if you want to\n",
        "# specify it manually, which is useful in some complex models.\n",
        "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imCTbN4ERREM"
      },
      "source": [
        "Example layers are Dense (a fully-connected layer), Conv2D, LSTM, BatchNormalization, Dropout, and many others.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "037mJEB3SEMw",
        "outputId": "3ff46a4a-b00c-40e3-9e86-8ac7e1c07d2c"
      },
      "source": [
        "# To use a layer, simply call it.\n",
        "layer(tf.zeros([10, 5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5fhm_N9SS0L",
        "outputId": "048cf827-2fd7-4ceb-ed9e-b39e19f88923"
      },
      "source": [
        "# Layer have many useful methods. For example, you can inspect all variables\n",
        "# in a layer using 'layer.variables' and trainable variables using \n",
        "# 'layer.trainable_variable'. In this case a fully-connected layer\n",
        "# will have variables for weights and biases.\n",
        "layer.variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
              " array([[ 0.20905888, -0.38080052,  0.16276693,  0.5383629 ,  0.21442747,\n",
              "          0.13619864,  0.26666003, -0.19832075,  0.0180136 ,  0.07614654],\n",
              "        [-0.37919158, -0.13683435,  0.2078464 ,  0.2016176 ,  0.07687306,\n",
              "         -0.12600166,  0.21432263,  0.21049851,  0.5052528 , -0.13991001],\n",
              "        [-0.35853574,  0.04692966,  0.31038183, -0.62749124,  0.28959072,\n",
              "          0.6207351 , -0.54864764, -0.50891596, -0.19068405,  0.21181697],\n",
              "        [ 0.1098609 , -0.00665313, -0.3480743 , -0.54486316,  0.23866546,\n",
              "         -0.38540816, -0.32521918,  0.23735994,  0.00598317,  0.28228468],\n",
              "        [-0.13930655, -0.13956425,  0.46567613, -0.60738593, -0.51548266,\n",
              "          0.02628058,  0.3067608 , -0.20731413, -0.16830602,  0.14127237]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE3M4r4KTXPK",
        "outputId": "0d4485b9-0e36-4720-c93d-875a61e92481"
      },
      "source": [
        "# The variables are also accessible through nice accessors\n",
        "layer.kernel, layer.bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
              " array([[ 0.20905888, -0.38080052,  0.16276693,  0.5383629 ,  0.21442747,\n",
              "          0.13619864,  0.26666003, -0.19832075,  0.0180136 ,  0.07614654],\n",
              "        [-0.37919158, -0.13683435,  0.2078464 ,  0.2016176 ,  0.07687306,\n",
              "         -0.12600166,  0.21432263,  0.21049851,  0.5052528 , -0.13991001],\n",
              "        [-0.35853574,  0.04692966,  0.31038183, -0.62749124,  0.28959072,\n",
              "          0.6207351 , -0.54864764, -0.50891596, -0.19068405,  0.21181697],\n",
              "        [ 0.1098609 , -0.00665313, -0.3480743 , -0.54486316,  0.23866546,\n",
              "         -0.38540816, -0.32521918,  0.23735994,  0.00598317,  0.28228468],\n",
              "        [-0.13930655, -0.13956425,  0.46567613, -0.60738593, -0.51548266,\n",
              "          0.02628058,  0.3067608 , -0.20731413, -0.16830602,  0.14127237]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqLawmCBT5w_"
      },
      "source": [
        "## **Implementing custom layers**\n",
        "The best way to implement your own layer is extending the tf.keras.Layer class and implementing:\n",
        "*  `__init__` , where you can do all input-independent initialization\n",
        "*  `build`, where you know the shapes of the input tensors and can do the rest of the initialization\n",
        "*  `call` where you do the forward computation\n",
        "\n",
        "Note that you don't have to wait until `build` is called to create your variables, you can also create them in `__init__`. However,\n",
        "*  The advantage of creating them in build is that it enables **late variable creation** based on the shape of the inputs the layer will operate on.\n",
        "*  On the other hand, creating variable in `__init__` would mean that **shapes required to create the variables will need to be explicitly specified.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TYwHb9VTxNj",
        "outputId": "4f752ba3-e240-4fea-a3e6-df048598b5c0"
      },
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_outputs):\n",
        "    super(MyDenseLayer, self).__init__()\n",
        "    self.num_outputs = num_outputs\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.kernel = self.add_weight(\"kernel\",\n",
        "                                  shape=[int(input_shape[-1]),\n",
        "                                         self.num_outputs])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "\n",
        "layer = MyDenseLayer(10)\n",
        "print(layer(tf.zeros([10, 5])))\n",
        "print()\n",
        "print(layer.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
            "\n",
            "[<tf.Variable 'my_dense_layer/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
            "array([[ 0.35589224, -0.5360265 ,  0.06197554, -0.27925608, -0.28954425,\n",
            "        -0.49069637, -0.05750704,  0.27957845,  0.13759267, -0.14388767],\n",
            "       [-0.04361773, -0.46767148, -0.25190127,  0.3751964 , -0.35982844,\n",
            "         0.11592895,  0.6024315 ,  0.4936903 ,  0.58209175,  0.35252905],\n",
            "       [-0.579371  ,  0.54324216, -0.21697927,  0.12442183,  0.21087438,\n",
            "        -0.45649394, -0.16855815, -0.22220168,  0.24416113,  0.28396434],\n",
            "       [ 0.40663797, -0.5538128 ,  0.2517696 , -0.48818755, -0.5996393 ,\n",
            "        -0.27014676, -0.4788531 ,  0.5759557 , -0.34730977,  0.5752794 ],\n",
            "       [ 0.5886552 , -0.15671048,  0.0171473 , -0.03810364,  0.08460897,\n",
            "        -0.40824836,  0.13450193,  0.38747126,  0.03929955,  0.02840853]],\n",
            "      dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAY2UR4qbhSQ"
      },
      "source": [
        "## **Automatic Differentiation**\n",
        "Automatic differentiation is a key technique for optimizing ML models.\n",
        "\n",
        "### **Gradient tapes**\n",
        "TenorFlow provides the `tf.GradientTape` API for automatic differentiation - computing the gradient of a computation with respect to its input variables.\n",
        "*  Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\"\n",
        "*  Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using `reverse mode differentiation.`\n",
        "\n",
        "For each example shown here, we will construct a computation graph and work out the derivatives. We compare the manually calculated derivatives with automatic differentiation.\n",
        "\n",
        "Any computation wrapped in a tape is recorded, and after the operations have happended you can request gradients from any Tensor to any variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeilo9GkYGVd",
        "outputId": "e4553d4b-0102-49f6-ead1-b433a89022ab"
      },
      "source": [
        "x = tf.Variable(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x ** 2\n",
        "  z = y ** 2\n",
        "dz_dx, dz_dy = tape.gradient(z, [x, y])\n",
        "print(dz_dx.numpy()) # 4.0\n",
        "print(dz_dy.numpy()) # 2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71UHn_THe86E"
      },
      "source": [
        "If you want to request a gradient from a tensor to another tensor, then you need to tell the tape to watch the source tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gl4ponKexYf",
        "outputId": "ae6d9d4a-6e13-4d4c-a900-fdab8e61887b"
      },
      "source": [
        "x = tf.constant(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x) # Since 'x' is not a variable we must explicitly \"watch\" it.\n",
        "  y = x ** 2\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx.numpy()) # 2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGCyzgU6gEVR"
      },
      "source": [
        "By default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computaion, create a presistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is gargbage collected. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx-MxyWOgADx",
        "outputId": "1faf2a49-7396-47e3-ea79-e9369472ab8f"
      },
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape(persistent=True) as t:\n",
        "  t.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "dz_dx = t.gradient(z, x) # 108.8 (4*x^3 at x == 3)\n",
        "dy_dx = t.gradient(y, x) # 6.0\n",
        "\n",
        "print(dy_dx)\n",
        "print(dz_dy)\n",
        "print(dz_dx)\n",
        "\n",
        "del t # Drop the reference to the tape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n",
            "tf.Tensor(108.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "456Q8QW8jIp8"
      },
      "source": [
        "## **Recording control flow**\n",
        "Because tapes record operations as they are executed, Python control flow (using ifs and whiles for example) in naturally handled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7WDdBXRhnRB"
      },
      "source": [
        "def f(x, y):\n",
        "  output = 1.0\n",
        "  for i in range(y):\n",
        "    if i > 1 and i < 5:\n",
        "      output = tf.multiply(output, x)\n",
        "  return output\n",
        "\n",
        "def grad(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    out = f(x, y)\n",
        "  return t.gradient(out, x)\n",
        "\n",
        "x = tf.convert_to_tensor(2.0)\n",
        "\n",
        "assert grad(x, 6).numpy() == 12.0\n",
        "assert grad(x, 5).numpy() == 12.0\n",
        "assert grad(x, 4).numpy() == 4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPU6hgeRlJjV"
      },
      "source": [
        "## **Higher-order gradients**\n",
        "Operations inside of the GradientTape context manager are recorded for automatic differentiation. If gradients are computed in that context, then the gradient computation is recorded as well. As a result, the exact same API works for higher-order gradient as well. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpZ0F8Kjkw-T"
      },
      "source": [
        "x = tf.Variable(1.0) # Create a Tensorflow variable initialized to 1.0\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  with tf.GradientTape() as t2:\n",
        "    y = x * x * x\n",
        "    # Compute the gradient inside the 't' context manager\n",
        "    # which mean the gradient computation if differentiable as well.\n",
        "    dy_dx = t2.gradient(y, x)\n",
        "d2y_dx2 = t.gradient(dy_dx, x)\n",
        "\n",
        "assert dy_dx.numpy() == 3.0\n",
        "assert d2y_dx2.numpy() == 6.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM7BmEg0nDfB"
      },
      "source": [
        "In This section, we covered gradient computation in TensorFlow. With that we have enough of the primitives required to build and train neural networks.\n",
        "\n",
        "## **Custom Training**\n",
        "Let's train neural networks from the first principle so as to acquire strong foundation understanding of the concepts. We use tf.Variable to represent weights in a model. A tf.Variable object stores a value and implicitly reads from this stored value. These are operatons (tf.assign_sub,tf.scatter_update. etc.) that manipulate the value stored in a TensorFlow variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAVANOF1nBVd"
      },
      "source": [
        " v = tf.Variable(1.0)\n",
        " # Use Python's 'assert' as a debugging statement to test the condition\n",
        " assert v.numpy() == 1.0\n",
        "\n",
        " # Reassign the value 'v'\n",
        " v.assign(3.0)\n",
        " assert v.numpy() == 3.0\n",
        "\n",
        " # Use 'v' in a Tensorflow 'tf.square()' operation and reassign\n",
        " v.assign(tf.square(v))\n",
        " assert v.numpy() == 9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6mtTBwRqs0M"
      },
      "source": [
        "## **Fit a linear model**\n",
        "Let's use the concepts you have learned so far-Tensor, Variable, and GradientTape-to build and train a simple model. This typically involves a few steps:\n",
        "1.  Define the model.\n",
        "2.  Define a loss function.\n",
        "3.  Obtain training data.\n",
        "4.  Run through the training data and use an \"optimizer\" to adjust the variable to fit the data.\n",
        "\n",
        "Here, you'll create a simple linear model, f(x) = x * W + b, which has two variables: W(weights) and b(bias). You'll synthesize data such that a well trained model would have W = 3.0 and b = 2.0.\n",
        "\n",
        "## **Define the model**\n",
        "Let's define a simple class to encapsulate the variables and the computation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qppbn53mqqwW",
        "outputId": "1152e0a8-0f55-403b-c055-a2a46c9e927d"
      },
      "source": [
        "class MyModel(tf.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    # Initialize the weights to `5.0` and the bias to `0.0`\n",
        "    # In practice, these should be randomly initialized\n",
        "    self.w = tf.Variable(5.0)\n",
        "    self.b = tf.Variable(0.0)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.w * x + self.b\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# List the variables tf.modules's built-in variable aggregation.\n",
        "print(\"Variables:\", model.variables)\n",
        "\n",
        "# Verify the model works\n",
        "assert model(3.0).numpy() == 15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variables: (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiylHeX-tHAL"
      },
      "source": [
        "## **Define a loss function**\n",
        "A loss function measures how well the output of a model for a given input matches the target output. The goal is to minimize this difference during training. Let's use the standard L2 loss, also known as the least square errors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bib9fdErtCgd"
      },
      "source": [
        "# This computes a single loss value for an entire batch\n",
        "def loss(target_y, predicted_y):\n",
        "  return tf.reduce_mean(tf.square(target_y - predicted_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuSHRipguiky"
      },
      "source": [
        "## **Obtain training data**\n",
        "First, synthesize the training data by adding random Gaussian (Normal) noise to the inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gvPpt-GueHr"
      },
      "source": [
        "# The actual line\n",
        "TRUE_W = 3.0\n",
        "TRUE_B = 2.0\n",
        "\n",
        "NUM_EXAMPLES = 1000\n",
        "\n",
        "# A vector of random x values\n",
        "x = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "\n",
        "# Generate some noise\n",
        "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "\n",
        "# Calculate y\n",
        "y = x * TRUE_W + TRUE_B + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npoPUuJUvVYR"
      },
      "source": [
        "Before training the model, visualie the loss value by plotting the model's predictions in red and the training data im blue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-6A45ty0vUcx",
        "outputId": "eba2998c-518c-47fe-ca54-18882182247b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x, y, c = 'b')\n",
        "plt.scatter(x, model(x), c = 'r')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %1.6f' % loss(model(x), y).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 9.091275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjm9go7AwSBR"
      },
      "source": [
        "## **Define a training loop**\n",
        "With the network and training data, train the model using gradient descent to update the weights variable (W) and the bias variable (b) to reduce the loss. There are many of the gradient descent scheme that are captured in `tf.train.Optimizer-`our recommended implementation. But in the spirit of building from first principles, here you will implement the basic math yourself with the help of `tf.GradientTape` for automatic differentiation and `tf.assign_sub` for decrementing a value (which combines tf.assign and tf.sub):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgCpxG0HwC95"
      },
      "source": [
        "# Given a callable model, inputs, outputs, and a learning rate...\n",
        "def train(model, x, y, learning_rate):\n",
        "\n",
        "  with tf.GradientTape() as t:\n",
        "    # Trainable variables are automatically tracked by GradientTape\n",
        "    current_loss = loss(y, model(x))\n",
        "\n",
        "  # Use GradientTape to calculate the gradients with respect to W and b\n",
        "  dw, db = t.gradient(current_loss, [model.w, model.b])\n",
        "\n",
        "  # Subtract the gradient scaled by the learning rate\n",
        "  model.w.assign_sub(learning_rate * dw)\n",
        "  model.b.assign_sub(learning_rate * db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08w3-7ZQtbwV"
      },
      "source": [
        "Finally, let's repeatedly run through the training data and see how W and b evolve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNqL7dMtZRs"
      },
      "source": [
        "model = MyModel()\n",
        "\n",
        "# Collect the history of W-values and b-values to plot later\n",
        "Ws, bs = [], []\n",
        "epochs = range(10)\n",
        "\n",
        "# Define a training loop\n",
        "def training_loop(model, x, y):\n",
        "\n",
        "  for epoch in epochs:\n",
        "    # Update the model with the single giant batch\n",
        "    train(model, x, y, learning_rate=0.1)\n",
        "\n",
        "    # Track this before I update\n",
        "    Ws.append(model.w.numpy())\n",
        "    bs.append(model.b.numpy())\n",
        "    current_loss = loss(y, model(x))\n",
        "\n",
        "    print(\"Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f\" %\n",
        "          (epoch, Ws[-1], bs[-1], current_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "xDQXG7WmvSLr",
        "outputId": "0c879d4b-d7e1-47e1-d88c-312738c660a2"
      },
      "source": [
        "print(\"Starting: W=%1.2f b=%1.2f, loss=%2.5f\" %\n",
        "      (model.w, model.b, loss(y, model(x))))\n",
        "\n",
        "# Do the training\n",
        "training_loop(model, x, y)\n",
        "\n",
        "# Plot it\n",
        "plt.plot(epochs, Ws, \"r\",\n",
        "         epochs, bs, \"b\")\n",
        "\n",
        "plt.plot([TRUE_W] * len(epochs), \"r--\",\n",
        "         [TRUE_B] * len(epochs), \"b--\")\n",
        "\n",
        "plt.legend([\"W\", \"b\", \"True W\", \"True b\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting: W=5.00 b=0.00, loss=9.09128\n",
            "Epoch  0: W=4.62 b=0.41, loss=6.26713\n",
            "Epoch  1: W=4.30 b=0.73, loss=4.43387\n",
            "Epoch  2: W=4.05 b=0.99, loss=3.24357\n",
            "Epoch  3: W=3.85 b=1.20, loss=2.47056\n",
            "Epoch  4: W=3.68 b=1.37, loss=1.96843\n",
            "Epoch  5: W=3.54 b=1.50, loss=1.64219\n",
            "Epoch  6: W=3.43 b=1.61, loss=1.43018\n",
            "Epoch  7: W=3.34 b=1.69, loss=1.29237\n",
            "Epoch  8: W=3.27 b=1.76, loss=1.20277\n",
            "Epoch  9: W=3.21 b=1.82, loss=1.14451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXTV5Z3H8fdjEghgghBQlgQSEJBFCW1kSWwHRUVQS1vcBUtnFMVpFQp11KlTOto67QGLVdBS7VgFLIpLlQGt1aLFoJYlSllEiyxhKYSlIIuQ8MwfXy43yb1AIjf5/ZJ8Xuf8zl1+9958c0/4nIfn9yzOe4+IiITXaUEXICIiJ6agFhEJOQW1iEjIKahFREJOQS0iEnLJNfGhrVq18tnZ2TXx0SIi9dKSJUtKvPet452rkaDOzs5m8eLFNfHRIiL1knNu/fHOqetDRCTkFNQiIiGnoBYRCbka6aMWEQE4fPgwxcXFHDx4MOhSQiM1NZXMzExSUlKq/B4FtYjUmOLiYtLS0sjOzsY5F3Q5gfPes2PHDoqLi8nJyany+9T1ISI15uDBg2RkZCikj3LOkZGRUe3/YSioRaRGKaQr+jLfR7iC+v774Y03QEuviogcE56g3rMHpk2DSy+Fnj3h8cdh376gqxKROm7cuHFMmTLl2OPBgwdz8803H3s8fvx4HnrooSBKq7LwBHV6OqxbB7/7HTRpAmPGQFYW3HUXrD/uhB0RkRMqKCigsLAQgCNHjlBSUsKKFSuOnS8sLCQ/Pz+o8qokPEEN0Lgx3HQTLF4MCxfCxRfDQw9Bp05w1VXwzjvqFhGRasnPz2fRokUArFixgl69epGWlsauXbv44osvWLVqFV/5ylcCrvLEwjk8zzkoKLBj40aYOhV+8xt44QXo0wfuuAOuuw5SU4OuVESqauxYKCpK7Gfm5kK5bo142rVrR3JyMhs2bKCwsJABAwawadMmFi1aRPPmzTn33HNp1KhRYutKsHC1qOPJyoL/+R8L7OnT4dAh+O53oUMHuO8+2Lw56ApFJOTy8/MpLCw8FtQDBgw49rigoCDo8k4qnC3qeJo2hVtugZtvhrfegocfhp/+1EL8mmvgzjuhb9+gqxSR4zlJy7cmRfqply9fTq9evcjKymLy5Mmkp6fz3e9+N7C6qir8LerKnINBg+CVV+CTT+B734NXX4V+/WDAAHj2WTh8OOgqRSRE8vPzmTt3Li1btiQpKYmWLVuye/duFi1aFPoLiVAXg7q8zp3hl7+ETZvgV7+CHTvghhsgO9ta29u3B12hiITAueeeS0lJCf3796/wXPPmzWnVqlWAlVWN8zUwiiIvL88HsnHAkSPw2mvWLfLHP9ookhtusG6R3r1rvx6RBm7VqlV079496DJCJ9734pxb4r3Pi/f6ut2iruy002DoUHj9dVixwi46zp5tV4YHDoSXXoKysqCrFBGplvoV1OX16AGPPQbFxfCLX8Bnn8G3v23dJZMmwa5dQVcoIlIl9TeoI1q0gB/+EP7+dxuH3bGjPc7MhNtvh9Wrg65QROSE6n9QRyQnW4v67bdh6VIb0vfkk9C9OwweDPPmWR+3iEjINJygLq9PH/jf/7VJNPffD8uXw+WXW2g/+ijs3Rt0hSIixzTMoI4480z40Y9sMaiZM+GMM+D737dukVtugT//WRcfRSRwDTuoIxo1smF8778P770Hw4bB738PF11kU9XHj4clS7QglEgdtG7dOnr16hV0GadEQV1Zv37w9NPwj3/Y0L7zz4dHHoG8PDjnHPjJT2DNmqCrFJEGREF9PE2b2gXHl1+GrVtt9b727S2ou3WzAP/lL7UolEgdUFpayo033kj37t256qqr2L9/f9AlVUv9mplYGzZtspb2rFnWHeIcXHihdZ18+9s2HFBEgIoz8AJa5ZR169aRk5PDwoULKSgo4F//9V/p0aMHEyZMSGwx1dCwZybWhvbt4Qc/sM0NVq+G//ovGz1y883Qpg1861vw/PNw4EDQlYrIUVlZWceWMx0xYgQLFy4MuKLqqTvLnIZRt24wcSL8+MfWup41yy5CvvwynH66tbBvuMFW+0vWVy0NW4CrnMbs/F3XdkZXizoRnLOLjQ89ZK3rN9+Ea6+FP/wBLrsM2rWzYX+LFmnkiEgANmzYcGw7rlmzZnHBBRcEXFH1KKgTLSnJhvU98YSNHHnpJVsQ6oknID/f9n/8z/+0RaNEpFZ069aNqVOn0r17d3bt2sWYMWOCLqla9P/xmtS4MXzzm3bs2WNdIrNmwc9/Dj/7GZx3nnWNXHedrUEiIgmXnZ3N6jq+po9a1LUlPd12WH/tNRs58sgj0KwZ3H23bXTwta/Zan8lJUFXKiIho6AOwlln2RZihYWwdq3tRrNzp63m17atrTsyY4bWHBERoBpB7ZxLcs4tc87NrcmCGpycHLj3Xvjb3+DDD2HCBLs/cqStRTJ0qLW+P/006EpFJCDVaVHfCayqqUIaPOesz/rBB22Tg4ULYfRoC+g77oAuXey44w6YP1/jtEUakCoFtXMuE7gceKJmyxHAthQrKLC9H9essbB+5BHo2tVGjwwdCi1bwpAhtqnvJ58EXbGI1KCqtqinAHcBx11Z3zk32jm32Dm3eLt2/06szp2tT/v//s92Wn/tNbj1VuvfvvNOC/Czz7ax2vPmQR1bx0BETuykQe2cuwLY5r1fcqLXee+ne+/zvPd5rVu3TliBUkmTJrYjzZQp8PHHtsXYo4/ayn5PPmkXIjMybKLNww+rtS0N2o4dO8jNzSU3N5c2bdrQvn37Y48PHTp0yp//hz/8gW9+85vHHj/44IOcffbZxx6/+uqrfOMb3zjln1OVFnUB8A3n3Drg98BFzrkZp/yTJTE6dYJ//3eYO9dGjrz+urW2P/vMVsGJtLYjLXK1tqUBycjIoKioiKKiIm677TbGjRt37HGjRo0oLS09pc/Pz8/nvffeO/Z40aJFpKens23bNgAKCwvJz88/pZ8BVQhq7/093vtM7302cB3wlvd+xCn/ZEm81FS49NL4re3f/hauuML6tiOt7TVrNKVdGpxRo0Zx22230a9fP+666y4mTpzIpEmTjp3v1asX69atA2DGjBn07duX3Nxcbr31Vsoq7fjUunVr0tPT+fToqKxNmzYxfPhwCgsLAQvqyGJQp0LjqOuzeK3tMWNs67GxY21RKbW2pTYNHBh7TJtm5/bvj3/+qafsfElJ7Lkvqbi4mMLCQh566KHjvmbVqlXMnj2bd999l6KiIpKSkpg5c2bM6woKCigsLOTjjz+mS5cu9O/fn8LCQkpLS/nwww85//zzv3SdEdWaQu69XwAsOOWfKrUv0tq+9FLb8OCzz2yY3/z5ttHv1Kk25f1f/sVGkwwZYt0mdWyVMZGquPrqq0lKSjrha958802WLFlyLGgPHDjAmWeeGfO6/Px8CgsLKSsrY8CAAfTt25f//u//ZtmyZZxzzjmkpqaecr1a66OhysmxmZC33w4HD8Jf/hIN7nHj7MjJscAePNiGC2ZkBF211HULFhz/XNOmJz7fqtWJz1dDs2bNjt1PTk7myJHogLaDBw8C4L3nO9/5Dg8++OAJP6ugoIBHHnmEsrIybrnlFtLS0jh48CALFixISP80qOtDwFrbl1xiy7SuWmXD/qZNg1697L+dw4bZP5IePWx39t/9zsZ2q39b6oHs7GyWLl0KwNKlS/nss88AGDRoEHPmzDl2YXDnzp2sX78+5v3du3dn8+bNLFy4kD59+gCQm5vL448/npD+aVBQSzw5OdaX/cor1rf99tu22l9ODsyZA6NG2SzJtm1h+HAL+PffhwQMdxKpbcOHD2fnzp307NmTRx99lK5duwLQo0cPHnjgAS699FLOO+88LrnkErZs2RLzfucc/fr1IyMjg5SUFAAGDBjA2rVrE9ai1p6JUj1HjsDKlfDuu3YsXGj93WBjvPv2tW6SCy6AAQPgjDOCrVcCFW9vQKn+nonqo5bqOe006xLp1cvGawNs2RIN7Xffja637Rz07GmhXVBgR3a2LlCKVJOCWk5d27Zw1VV2AOzbZ10hkVb3zJnw+ON2rl27aIu7oAB699Z+kiInoX8hknjNmtl2ZBddZI/Lymzp1vKt7uefj762f/9oi7t/f9tkQUSOUVBLzUtKspZz7942HBBsE+BIi/vdd+GBB6z/+7TTbLnX8q3urKxg6xcJmIJagpGVZXtFXnedPd6zx7pLIi3up56ySTiR115wgbW2c3Mt8Js3D6x0kdqmoJZwSE+3sdyXXGKPS0ttx5tIi/vtt+HZZ6Ovz8mBPn0suCNHZqYuVEq9pKCWcEpOhq9+1Y477rDJNVu3QlGRHcuW2e2LL0bf07JlNLQjId6tGxwd2yoNz44dOxg0aBAAW7duJSkpicgyzB988AGNGjU65Z+RnZ3N4sWLadWq1Sl/1vEoqKVucM5Gl7Rta9PaI/buheXLKwb41KnwxRd2vnFjG0pYPsDPOw/S0oL5PaRWRZY5BZg4cSKnn346EyZMOHa+tLSU5Dow6ij8FYqcSFoa5OfbEVFaasu8RsK7qAheftk2Vog4++yK3Sa5uTZ0UF0n9d6oUaNITU1l2bJlFBQUkJ6eXiHAe/Xqxdy5c8nOzmbGjBn86le/4tChQ/Tr149p06bFXczpF7/4BfPnz6dJkybMmjWrwuYBiaCglvonOdkm2vTsCTfeaM95D5s2VQzvZctsSnxE69ax4d21q8Z5J1C8lUmvucYGA+3fb9uBVjZqlB0lJdGh+hFfdo2myDKnSUlJTJw4Me5ryi9zmpKSwu23387MmTO56aabYl7bvHlzli9fztNPP83YsWOZO3fulyvsOPQXKA2Dc3axMTPTNlCI2LPHLlqWD/CHH46uW5Kaal0l5cO7Z0+N9a7jErnMKcD1119/7HbcuHGJLRYFtTR06enwta/ZEXH4MKxeXfGi5fPPw/Tp0de0aWMXKs85x24jR3a2jRuXuEKyymlClzkFW5gp3v1EUVCLVJaSAueea8fIkfac9zZJZ9kyWwr244/teO452LUr+t5Gjaz/OxLc5YO8RYtgfh85oezs7GNdFZWXOR02bBjjxo3jzDPPZOfOnezdu5eOHTvGfMbs2bO5++67mT17NgMGDEh4jQpqkapwDjp0sGPYsOjz3lvnaSS4I8fKlfDqq3ZhM6J164qt78jRqZOGEAZo+PDhPP300/Ts2ZN+/frFXeb0yJEjpKSkMHXq1LhBvWvXLs477zwaN27Ms+XH+yeIljkVqSmHD9sSsKtXxwb59u3R1yUnQ+fO8UO8Vas6PRJFy5zGp2VORcIiJcVGjRxtoVWwa1c0tMsH+WuvVdyAoUWL2H7wbt0s2Bs3rr3fRQKloBYJQosWtnZJ//4Vny8rs13iy7e+V6+2AI/sxg22eFVmpl28LH907Gi3WVnqTqlHFNQiYZKUZK3lzp1jBxX/85+wZk00wNets+Ott2yMePluzNNOg/btK4Z3+TDPyqq1Frn3vkZGQtRVX6a7WUEtUlc0bw7nn29HZYcOQXFxNLzXrYP16+32nXdg1ixbRjbCOZuJGS/Is7PtomkCgjw1NZUdO3aQkZGhsMZCeseOHaSmplbrfQpqkfqgUSMbPdKpU/zzhw9bq7tyiK9bB4WFMHu2dbuU17ZtbJdK+SBv0uSkZWVmZlJcXMz28hdPG7jU1FQyMzOr9R4FtUhDkJISDdl4Skth8+b4Qf7++zbV/vDhiu856ywL8PbtrXVe+WjblpSWLcnJyanJ36xBUFCLiA0RjIwT//rXY8+XldkmxpVDfP166zdfsKDixJ+Ixo2tZV4uvCuHOe3a2W716ho5LgW1iJxcUlJ0rZQLLoj/mgMHbM3wzZsrHlu22O2KFfDGG3ZRtLLU1OOHefnn0tMbZKArqEUkMZo0sZ13TtbVsX9/NLzjhfpHH9lwxL17Y9/btGn8QG/b1mZ+lj/q0ThzBbWI1K6mTaNDEE9k714L7nihvmULLF1q0/T374///rS0aGi3ahUb5JWPZs1C21pXUItIOKWl2RFvZmeE99FA37499igpsdvNm2052+3bo7v/VJaaWr1gr8V+dQW1iNRdzlm/dXq6Ta0/Ge/h88/jh3rlY80au923L/5nJSdXDPRWrWwi0aRJif0dUVCLSEPiXLSlfrwx55UdOBBtmZ/oiCyBWwMU1CIiJ9KkibWUs7ICK+G0wH6yiIhUiYJaRCTkFNQiIiGnoBYRCTkFtYhIyJ00qJ1zqc65D5xzHzrnVjjnflIbhYmIiKnK8LwvgIu8958751KAhc65+d7792q4NhERoQpB7W3fmM+PPkw5eiR+6/KIgQNjn7vmGrj9dpvTX3l7IoBRo+woKYGrroo9P2YMXHstbNwII0fGnh8/Hq680rY3uvXW2PM/+hFcfDEUFcHYsbHnf/YzyM+3BdjvvTf2/JQpkJsLf/oTPPBA7Plf/9pmVb36KkyeHHv+mWdsDOfs2fDYY7Hn58yxWVFPPVVxX72IefNsfYVp0+C552LPL1hgt5Mmwdy5Fc81aQLz59v9+++HN9+seD4jA154we7fcw8sWlTxfGYmzJhh98eOte+wvK5dYfp0uz96tM0GKy83174/gBEjbBeT8gYMgAcftPvDh8OOHRXPDxoE991n94cMsckL5V1xBUyYYPf1txd7Xn97dr+qf3uR3yfBqtRH7ZxLcs4VAduAN7z378d5zWjn3GLn3GLt5iAikjiuOhstOufOAF4Cvu+9/9vxXpeXl+cXL16cgPJERBoG59wS731evHPVGvXhvd8N/Bm4LBGFiYjIyVVl1Efroy1pnHNNgEuA1TVdmIiImKqM+mgL/M45l4QF+3Pe+7kneY+IiCRIVUZ9fAT0qYVaREQkDs1MFBEJOQW1iEjIKahFREJOQS0iEnIKahGRkFNQi4iEnIJaRCTkFNQiIiGnoBYRCTkFtYhIyCmoRURCTkEtIhJyCmoRkZBTUIuIhJyCWkQk5BTUIiIhp6AWEQk5BbWISMgpqEVEQk5BLSIScgpqEZGQU1CLiIScglpEJOQU1CIiIaegFhEJOQW1iEjIKahFREJOQS0iEnIKahGRkFNQi4iEnIJaRCTkFNQiIiGnoBYRCTkFtYhIyCmoRURCTkEtIhJyCmoRkZBTUIuIhNxJg9o5l+Wc+7NzbqVzboVz7s7aKExERExyFV5TCoz33i91zqUBS5xzb3jvV9ZwbSIiQhWC2nu/Bdhy9P5e59wqoD1QI0E9cGDsc9dcA7ffDvv3w9ChsedHjbKjpASuuir2/JgxcO21sHEjjBwZe378eLjySvj4Y7j11tjzP/oRXHwxFBXB2LGx53/2M8jPh8JCuPfe2PNTpkBuLvzpT/DAA7Hnf/1r6NYNXn0VJk+OPf/MM5CVBbNnw2OPxZ6fMwdatYKnnrKjsnnzoGlTmDYNnnsu9vyCBXY7aRLMnVvxXJMmMH++3b//fnjzzYrnMzLghRfs/j33wKJFFc9nZsKMGXZ/7Fj7Dsvr2hWmT7f7o0fDmjUVz+fm2vcHMGIEFBdXPD9gADz4oN0fPhx27Kh4ftAguO8+uz9kCBw4UPH8FVfAhAl2X397sef1t2f3q/q3F/l9Eq1afdTOuWygD/B+nHOjnXOLnXOLt2/fnpjqREQE572v2gudOx14G/ip9/7FE702Ly/PL168OAHliYg0DM65Jd77vHjnqtSids6lAC8AM08W0iIiklhVGfXhgCeBVd77h2q+JBERKa8qLeoCYCRwkXOu6OgR57KKiIjUhKqM+lgIuFqoRURE4tDMRBGRkFNQi4gkSFlZzXxuVWYmiog0OAcP2iSWkhK7LX//eM+lp9vkpkRTUItIvea9zSytHLInC+B9+47/mWlpNjOyVSu77dLF7rdtWzO/g4JaROoU7+Gf/4StW2HLFrv9xz9OHLxffHH8z2vRIhq67drBuedGAzhyW/l+o0a19/uCglpEQuKLLyxwt26tGMLxHscL3qQkaNkyGqo5OZCXd+LQbdECkutACtaBEkWkrvIedu48efBu3WqviyfSpdCmjS2k1KZN9HHkOOssOOMMOK2eDo9QUItItZWVWbhu2BA/dCPP/eMfcPhw7PubNImG7TnnwIUXVgzeyLkzz4SUlNr//cJGQS0iMfbtsxCOHOvXV7xfXAylpRXf45wFayRse/aMDd7IkZZmr5eqUVCLNDBHjsC2bccP4Q0bYtf1TkqC9u2hQwdb/7pjR7uflWUX4Nq0gdat60Z/b12kr1Wknjl40MbyHi+EN26MvRh3+unR8O3Xz247dIg+166dQjhI+upF6pi9e+HTT2Hdutgw3rDB+oXLc866Hjp2hK9+Fb71rYoh3KGDXYhTV0R4KahFQujQIVi71raHqnxs2VLxtU2aREO3d++KAdyxo3VZ1Pa4X0ksBbVIQI4csW6IeGG8bp2dj2jVyoamDR5st126QKdOFsYZGWoN13cKapEa5D1s3w6ffBIbxp9+av3JEc2aWQiffz7ceKPdj4RyixbB/Q4SPAW1SALs3Rs/jNessenOESkp0LmzBfBll1kIRwK5bVu1jCU+BbVIFZWVwd//DqtWxYZy5X7jDh0sfMu3jLt2tT5jjZ6Q6tKfjEgcn38OH30EH35oR1ERLF9uq7BFtG4dbRmXD+POne0Cn0iiKKilQfPeZtkVFVUM5b//3c6BDV3r3RtuucVue/SwQFa/sdQWBbU0GIcOwcqVsaG8a1f0NZ07WxjfdJPd5uba7Dv1HUuQFNRSL5WURIM4EsorV0bXp2jSxNYdvvpqC+TeveG882wNCpGwUVBLnVZWZsPcKofypk3R17RrZ0F8+eXRUO7SxdavEKkLFNRSZ+zdaxf0yody+Qt8ycnQvbstmZmbGw3l1q2DrVvkVCmoJZS8t5byu+9Gj1WroudbtLAQHj06Gsg9ekDjxsHVLFJTFNQSCocOwdKlFYN52zY7d8YZUFAA118fbSnrAp80JApqCcSuXVBYaIG8cCH89a/R6dSdOtnY5IICO7p3r79bLIlUhYJaapz3thJcpKW8cKGNwADrV/7KV2DMmGgwt2kTbL0iYaOgloQ7fBiWLasYzJE1kps3tx1CbrjBQrlvX2jaNNh6RcJOQS2nbPduWLQoGsoffAAHDti57Gy45JJoa7lnT3VjiFSXglqqxXtbK7l8a3nFCns+Kcku9o0eHQ3mdu2Crlik7lNQywmVlUW7MRYutNvISnFpadaNcc010W6M008Ptl6R+khBLTG2b4fXX4d58+x25057vkMHm0wSaS336qXZfSK1QUEtHDliY5jnzbPjgw+sK+PMM+HKK237p699DTIzg65UpGFSUDdQu3fDH/9owTx/vk0ucc66LyZOhKFDbdicLvyJBE9B3UB4b+tiRFrNhYXW/9yihU0uGTrUWs5aF0MkfBTU9djevfDmm9Fwjqwo16cP3H23hXPfvtoaSiTs9E+0HvEePv44GszvvGOTT9LS4NJLLZgvu0xD5kTqGgV1HXfgACxYEA3ntWvt+Z49YexYC+f8fGjUKNAyReQUnDSonXO/Ba4Atnnve9V8SXIyn30WDea33rLFjJo2hUGD4Ic/hCFDbLdrEakfqtKifgp4FHi6ZkuR4zl0CP7yl2g4r15tz3fpArfeaq3mr38dUlODrVNEasZJg9p7/45zLrvmS5HySkrgpZcsmP/0J/j8c1sUf+BAW2luyBALahGp/xLWR+2cGw2MBujQoUOiPrZBOXAA5s6FZ56xsc2lpTYbcORIazVfeCE0axZ0lSJS2xIW1N776cB0gLy8PJ+oz63vjhyx0RkzZsDzz8OePTYqY9w4uPFG2xlbO5mINGwa9RGQlSut5TxzJmzcaIsZDR9ureeBA7WGhohEKahr0dat8Oyz1npeutTCePBg+PnPYdgwLaAvIvFVZXjes8BAoJVzrhj4sff+yZourL7Ytw9eftlaz2+8YV0deXnw8MNw7bVw1llBVygiYVeVUR/X10Yh9UlZmU3dnjEDXnzRwrpjR7jnHhgxAs45J+gKRaQuUddHgngPH35oLednn7XF9Zs3t70BR4609Zu1Ep2IfBkK6lO0cSPMmmUBvWIFpKTA5Zdby/nyyzUJRUROnYL6S9izB+bMsa6NBQusNZ2fD489BldfDRkZQVcoIvWJgrqKDh+2bameeQZeecXW1zj7bFtk/8YboXPnoCsUkfpKQX0C3sNf/2rh/Pvf27TujAz4t3+zfue+fTUZRURqnoI6jrVrbSLKjBmwZo2tsTFsmPU7X3aZ9UOLiNQWBfVR3sPChTBpknVtgM0Q/I//sBmDzZsHWp6INGANPqhLS22s86RJ1s2RkQH33Qc332wLIomIBK3BBvXnn8OTT8KUKbBunV0YnDYNvvMdTeUWkXBpcEG9eTM88gg8/jjs3m0TUX75S7jySi2EJCLh1GCCevlymDzZJqeUlcG3vw3jx0P//kFXJiJyYvU6qL23NTcmTbIx0E2bwm232aavnToFXZ2ISNXUy6A+dAhmz7aA/ugjW6Hupz+1kG7ZMujqRESqp14F9e7dMH26LSG6eTP06AG//a0tjNS4cdDViYh8OfUiqNevt3D+zW9sNMegQTaiY/BgzRwUkbqvTgf14sV2gfD55+3xddfZBcI+fYKtS0QkkepcUB85AvPmWUAvWABpabYR7B13QFZW0NWJiCRenQnqgwdt7Y3Jk2H1agvlyZNtBmF6etDViYjUnNAHdUmJrfP86KOwbZt1a8ycaes+a3EkEWkIQhvUn3xiMwafegoOHIChQ2HCBFsoSRcIRaQhCV1QFxba+OeXX7YW88iR8IMf2FA7EZGGKDRBvWePDad77z2blHLvvfC970GbNkFXJiISrNAEdXq6TeseMQJGjYJmzYKuSEQkHEIT1GAXCUVEpKLTgi5AREROTEEtIhJyCmoRkZBTUIuIhJyCWkQk5BTUIiIhp6AWEQk5BbWISMg5733iP9S57cD6L/n2VkBJAsupy/RdVKTvoyJ9H1H14bvo6L1vHe9EjQT1qXDOLfbe5wVdRxjou6hI30dF+j6i6vt3oa4PEZGQU1CLiIRcGIN6eotd2koAAAKtSURBVNAFhIi+i4r0fVSk7yOqXn8XoeujFhGRisLYohYRkXIU1CIiIReaoHbOXeac+9g596lz7u6g6wmScy7LOfdn59xK59wK59ydQdcUNOdcknNumXNubtC1BM05d4Zzbo5zbrVzbpVzbkDQNQXJOTfu6L+TvznnnnXOpQZdU6KFIqidc0nAVGAI0AO43jnXkLezLQXGe+97AP2Bf2/g3wfAncCqoIsIiYeB17z35wC9acDfi3OuPXAHkOe97wUkAdcFW1XihSKogb7Ap977td77Q8DvgWEB1xQY7/0W7/3So/f3Yv8Q2wdbVXCcc5nA5cATQdcSNOdcc+DrwJMA3vtD3vvdwVYVuGSgiXMuGWgKbA64noQLS1C3BzaWe1xMAw6m8pxz2UAf4P1gKwnUFOAu4EjQhYRADrAd+N+jXUFPOOca7FbQ3vtNwCRgA7AF+Kf3/o/BVpV4YQlqicM5dzrwAjDWe78n6HqC4Jy7AtjmvV8SdC0hkQx8BXjMe98H2Ac02Gs6zrkW2P++c4B2QDPn3Ihgq0q8sAT1JiCr3OPMo881WM65FCykZ3rvXwy6ngAVAN9wzq3DusQucs7NCLakQBUDxd77yP+w5mDB3VBdDHzmvd/uvT8MvAjkB1xTwoUlqP8KdHHO5TjnGmEXA14JuKbAOOcc1ge5ynv/UND1BMl7f4/3PtN7n439Xbzlva93Laaq8t5vBTY657odfWoQsDLAkoK2AejvnGt69N/NIOrhxdXkoAsA8N6XOue+B7yOXbX9rfd+RcBlBakAGAksd84VHX3uXu/9vABrkvD4PjDzaKNmLfDdgOsJjPf+fefcHGApNlpqGfVwOrmmkIuIhFxYuj5EROQ4FNQiIiGnoBYRCTkFtYhIyCmoRURCTkEtIhJyCmoRkZD7f0WvSbYrLCMZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6uq1SL9e34yR",
        "outputId": "e7c25a56-45b5-4ccd-9e9f-6bb5ea7aa321"
      },
      "source": [
        "# Visualize how the trained model performs\n",
        "plt.scatter(x, y, c=\"b\")\n",
        "plt.scatter(x, model(x), c=\"r\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Current loss: %1.6f\" % loss(model(x), y).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 1.144507\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}