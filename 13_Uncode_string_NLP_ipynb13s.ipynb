{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13.Uncode_string_NLP.ipynb13s",
      "provenance": [],
      "authorship_tag": "ABX9TyMaXtwAQ9zjll63JhUHD0g8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/13_Uncode_string_NLP_ipynb13s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-XBaRnAlVoB"
      },
      "source": [
        "# Unicode strings\n",
        "\n",
        "Models that process natural language often handle different language with different character sets. *Unicode* is a stanard encoding system that is used to represent character from almost all language. Each character is encoded using a unique integer code point between 0 and 0x10FFFF. A *Unicode string* is a sequence of zero or more code points.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE98qesilTL7"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlobQXr_mkGi"
      },
      "source": [
        "### The tf.string data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv8TgLK1mgXh",
        "outputId": "2ac76a17-b0fc-4855-cb10-b5bae563418d"
      },
      "source": [
        "tf.constant(u\"Thanks üòä\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXxSsC_5m5Qb",
        "outputId": "99b3e012-fdf9-4fb0-fcf3-41ae54d25331"
      },
      "source": [
        "tf.constant([u\"You're\", u\"welcome!\"]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIyxQpvVnGbC"
      },
      "source": [
        "### Representing Unicode\n",
        "\n",
        "There are two standard ways to repreent a Unicode string in Tensorflow:\n",
        "\n",
        "\n",
        "*   `string` scalar - where the sequence of code points in encoding using a known character encoding.\n",
        "\n",
        "*   `int32` vector - Where each position contains a single code point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6gHc-Vn5ax",
        "outputId": "c4779e2b-f34f-4870-ef6c-36382375117d"
      },
      "source": [
        "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
        "text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
        "text_utf8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSsBmwyyoLXq",
        "outputId": "f2ece68f-aeec-4697-ca19-f6659c44c956"
      },
      "source": [
        "# Unicode string, represent as a UTF-16-BE encoded string scalar.\n",
        "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\"))\n",
        "text_utf16be"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfrlfXy0oniP",
        "outputId": "a2725bae-af5c-4c13-b639-43fb9b7c97e8"
      },
      "source": [
        "# Unicode string, represent as a vector of Unicode code points.\n",
        "text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"])\n",
        "text_chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qg03aUzpD_S"
      },
      "source": [
        "### Converting between representations\n",
        "\n",
        "TensorFlow provides operations to convert between these different representation:\n",
        "\n",
        "*   `tf.string.unicode_decode`: Convert an encoded string scalar to a vector of code points.\n",
        "*   `tf.string.unicode_encode`: Convert a vector of code points to an encoded string scalar.\n",
        "*   `tf.string.unicode_transcode`: Convert an encoded string scalar to a different encoding.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKFK41eNpBPn",
        "outputId": "505bd939-fccd-422f-ee17-02ee99ea9ee2"
      },
      "source": [
        "tf.strings.unicode_decode(text_utf8,\n",
        "                         input_encoding='UTF-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91lQCwCRqqvM",
        "outputId": "c74463d4-2270-4df4-9fc0-734a82152079"
      },
      "source": [
        "tf.strings.unicode_encode(text_chars,\n",
        "                          output_encoding='UTF-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYS2piJaq4S8",
        "outputId": "f006041a-a814-487c-ee46-e919aa47c3fa"
      },
      "source": [
        "tf.strings.unicode_transcode(text_utf8,\n",
        "                             input_encoding=\"UTF8\",\n",
        "                             output_encoding=\"UTF-16-BE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb9545GCrSRO"
      },
      "source": [
        "### Batch dimensions\n",
        "\n",
        "When decoding multiple strings, the number of character in each string may not be equal. The return is a `tf.RaggedTensor`,Where the length of the innermost dimension varies depending on the number of characters in each string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOR9l6WPrQzu",
        "outputId": "f9f7b4f0-53ad-4069-9f5b-a54983d77913"
      },
      "source": [
        "# A batch of Unicode string each represented as a UTF8-encoded sring.\n",
        "batch_utf8 = [s.encode('UTF-8') for s in \n",
        "              [u'h√Éllo',  u'What is the weather tomorrow',  u'G√∂√∂dnight', u'üòä']]\n",
        "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
        "                                               input_encoding='UTF-8')\n",
        "for sentence_chars in batch_chars_ragged.to_list():\n",
        "  print(sentence_chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[104, 195, 108, 108, 111]\n",
            "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
            "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
            "[128522]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCa6Mti2tFqA"
      },
      "source": [
        "You can use this `tf.RaggedTensor` directly,or convert it to dense `tf.Tensor`with padding or a tf.SparseTensor using the method `tf.RaggedTensor.to_tensor` and `tf.RaggedTensor.to_sparse`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygcFM3ytEzJ",
        "outputId": "8f77cb67-c778-4f41-bc2f-182524ecb248"
      },
      "source": [
        "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
        "print(batch_chars_padded.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
            " [    87    104     97    116     32    105    115     32    116    104\n",
            "     101     32    119    101     97    116    104    101    114     32\n",
            "     116    111    109    111    114    114    111    119]\n",
            " [    71    246    246    100    110    105    103    104    116     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
            " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
            "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qousBRQt8HG"
      },
      "source": [
        "batch_chars_sparse = batch_chars_ragged.to_sparse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNNG-Rsc0Yun"
      },
      "source": [
        "When encoding multiple string with the same length, a `tf.Tensor` may be used as input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Z8kyAUuI9I",
        "outputId": "1d8b8c74-3701-42ff-9169-244ecc32f8d8"
      },
      "source": [
        "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n",
        "                          output_encoding='UTF-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smWHQhGP4dCg"
      },
      "source": [
        "When encoding multiple string with varing length, a `tf.RaggedTensor` should be used as input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jDwcD1x5QBn",
        "outputId": "d24c7794-f404-4768-daf4-cfa0aa570c5a"
      },
      "source": [
        "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
              "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
              "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftm_z_J56mCf"
      },
      "source": [
        "If you have a tensor with multiple string in padded or sparse format,then convert it to a `tf.RaggedTensor` before calling unicode_encode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLKFrnUW6gHh",
        "outputId": "9cf3b340-3427-4a0e-8b03-bb3ae2dbd75e"
      },
      "source": [
        "tf.strings.unicode_encode(\n",
        "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
        "    output_encoding='UTF-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
              "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
              "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1RSeQvb7Q90",
        "outputId": "4740ff1b-de52-4f7a-e07b-4758a41fda4e"
      },
      "source": [
        "tf.strings.unicode_encode(\n",
        "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
        "    output_encoding='UTF-8'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
              "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
              "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ahhsSaH7xDb"
      },
      "source": [
        "## Unicode operations\n",
        "\n",
        "### character length\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ9fnao18YYu",
        "outputId": "a88de34a-2127-4d35-8dc1-18e39a2e4f17"
      },
      "source": [
        "#Note that the final character takes up 4 bytes in UTF8\n",
        "thanks = u'Thanks üòä'.encode('UTF-8')\n",
        "num_bytes = tf.strings.length(thanks).numpy()\n",
        "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
        "print('{} bytes; {} UTF-8 character'.format(num_bytes, num_chars))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 bytes; 8 UTF-8 character\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBoBsvDF9UfF"
      },
      "source": [
        "### Character substrings\n",
        "\n",
        "Similarly, the `tf.strings.substr` operation accepts the \"unit\" parameter, uses it to determine what kind of offsets the \"pos\" and \"len\" parameters contains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I22uFkCQ9PLW",
        "outputId": "00a4b4d9-662e-4dc8-bdc0-883c9e608ec7"
      },
      "source": [
        "# default: unit='BYTE'. With len=1, we return a single byte.\n",
        "tf.strings.substr(thanks, pos=5, len=3).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b's \\xf0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxFJkuHO-8oD",
        "outputId": "e70185e0-a9b2-4880-9176-716076b0cf00"
      },
      "source": [
        "# Specifying unit='UTF8_CHAR', we return a single character, which in this case \n",
        "# is 4 bytes.\n",
        "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\xf0\\x9f\\x98\\x8a'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4tdqB2O_ncd"
      },
      "source": [
        "### Split Unicode strings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k06fyF2Z_u8C",
        "outputId": "da7bba9d-2b52-486e-e72a-b14b9be0ed57"
      },
      "source": [
        "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIi3zOy__4V"
      },
      "source": [
        "### Byte offsets for character\n",
        "\n",
        "To align the character tensor generated by `tf.strings.unicode_decode` with the original string, it's useful to know the offset for where each character begins. The method `tf.strings.unicode_decode_with_offsets` is similar to `unicode_decode`, except that it return a second tensor containing the start offset of each character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcxCEw3RA_Uy",
        "outputId": "ed31ac80-42f0-4cc1-b022-f29d545dc43e"
      },
      "source": [
        "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"üéàüéâüéä\", 'UTF-8')\n",
        "\n",
        "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
        "  print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At byte offset 0: codepoint 127880\n",
            "At byte offset 4: codepoint 127881\n",
            "At byte offset 8: codepoint 127882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRGauozTBjn1"
      },
      "source": [
        "## Unicode scripts\n",
        "\n",
        "Each Unicode code point belong to single collection of codepoints known as a [script](https://en.wikipedia.org/wiki/Script_%28Unicode%29). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE0nCoZJCR43",
        "outputId": "080d2b74-1ee3-498e-a57d-3c4227f347e5"
      },
      "source": [
        "uscript = tf.strings.unicode_script([33464,1041]) # ['Ëä∏', '–ë']\n",
        "\n",
        "print(uscript.numpy()) #[17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz1rlS-BCu6F",
        "outputId": "cc011eb5-37da-47a5-95b6-98e1cce73082"
      },
      "source": [
        "print(tf.strings.unicode_script(batch_chars_ragged))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdFum9pMDNya"
      },
      "source": [
        "## Example: Simple segmentation\n",
        "\n",
        "Segmentation is the task of splitting text into word-like units. This is often easy when space characters are used to separate words, but some language(like chinese and Japanese) do not use spaces, and some language(like German) conatin long compounds that must be split in order to analyse their meaning. In web text, different language ans scripts are frequently mixed together, as in \"NYÊ†™‰æ°\"(New York Stock Exchange).\n",
        "\n",
        "We can perform very rough segmentation(without implementing any ML models) by using changes in script to approximate word boundaries. This will work for string like the \"NYÊ†™‰æ°\" example above. It will also work for most languages that use spaces, as the spaces characters of various scripts are all classified as USCRIPT_COMMON, a special scripts code that differs from that of any actual text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPzpBjPdEsXy"
      },
      "source": [
        "# dtype: string; shape: [num_sentences]\n",
        "# The sentence to process. Edit this line to try out different inputs!\n",
        "\n",
        "sentence_texts = [u'Hello, world.', u'‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiHEXSNTGK2V"
      },
      "source": [
        "Decode the sentences into character codepoints, and find the script identifeis for each character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISHC5TVVGJfm",
        "outputId": "1e80ab39-f69b-40a5-f3aa-590fc081de5e"
      },
      "source": [
        "# dtype : int32; shape[num_sentences, (num_chars_per_sentence)]\n",
        "\n",
        "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
        "# i'th sentence.\n",
        "\n",
        "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
        "print(sentence_char_codepoint)\n",
        "\n",
        "# dtype : int32; shape[num_sentences, (num_chars_per_sentence)]\n",
        "\n",
        "# sentence_char_codepoint[i, j] is the unicode script of the j'th character in the\n",
        "# i'th sentence.\n",
        "\n",
        "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
        "print(sentence_char_script)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
            "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AESNzes1HvKF"
      },
      "source": [
        "Next, we use those script identifiers to determine where word boundaries should be added. We add a word boundary at the beginning of each sentence, and for each character whoses script differs from the previous character:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSkLQ3qwHuh_",
        "outputId": "75a8b779-c095-42f9-a37c-b79ef0cfe1aa"
      },
      "source": [
        "# dtype : bool; shape : [num_sentences, (num_chars_per_sentence)]\n",
        "\n",
        "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th \n",
        "# sentence is the start of a word.\n",
        "sentence_char_starts_word = tf.concat(\n",
        "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
        "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
        "     axis=1)\n",
        "\n",
        "# dtype: int64 ; shape : [num_words]\n",
        "\n",
        "#word_starts[i] is the index of the character that starts with the i'th word (in\n",
        "# the flattened list of characters from all sentences).\n",
        "\n",
        "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
        "print(word_starts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O-axxAKKqfh"
      },
      "source": [
        "We can then use those start offset to build a `RaggedTensor` containing the list of words from all batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKHSysSSK63b",
        "outputId": "2bd746cf-80bb-4fd2-ddfa-fedc30cb8d93"
      },
      "source": [
        "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
        "#\n",
        "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
        "# i'th word.\n",
        "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
        "    values=sentence_char_codepoint.values,\n",
        "    row_starts=word_starts)\n",
        "print(word_char_codepoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw4tAvV1M0Gb",
        "outputId": "1309fe7c-fab0-43b8-f0da-7bf5bd9c53d6"
      },
      "source": [
        "# dtype: int64; shape: [num_sentences]\n",
        "#\n",
        "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
        "sentence_num_words = tf.reduce_sum(\n",
        "    tf.cast(sentence_char_starts_word, tf.int64),\n",
        "    axis=1)\n",
        "\n",
        "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
        "#\n",
        "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
        "# in the j'th word in the i'th sentence.\n",
        "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
        "    values=word_char_codepoint,\n",
        "    row_lengths=sentence_num_words)\n",
        "print(sentence_word_char_codepoint)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZRnHqEUM14f",
        "outputId": "748ec637-a19a-42da-b6fc-274885c79a46"
      },
      "source": [
        "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[b'Hello', b', ', b'world', b'.'],\n",
              " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
              "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}