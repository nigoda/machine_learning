{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "28_Simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp2wPQCAajZ+M++ccdmD4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/28_Simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "natwmJayE_OK"
      },
      "source": [
        "# **Simple RNN**\n",
        "\n",
        "The process we just naively implemented in Numpy corresponds to an actual Keras layer: the SimpleRNN layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rTWdmcEr-B"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNECnb6GFl-u"
      },
      "source": [
        "timesteps = 100        # Number of timesteps in the input sequence.\n",
        "input_feature = 32     # Dimensionality of the input feature space.\n",
        "out_feature = 64       # Dimensionality of the output feature space.  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEYXimBKGPOl"
      },
      "source": [
        "Get the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAhbWGPvGOLR",
        "outputId": "7c3d9dfc-ef91-4f3d-f483-35b859eb2c69"
      },
      "source": [
        "inputs = np.random.random((timesteps, input_feature))\n",
        "inputs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44603114, 0.1238897 , 0.15387167, ..., 0.36176625, 0.19393007,\n",
              "        0.1791747 ],\n",
              "       [0.21220262, 0.79783966, 0.39454305, ..., 0.15504415, 0.37042054,\n",
              "        0.34735725],\n",
              "       [0.00120405, 0.56023748, 0.65233289, ..., 0.53356833, 0.85795457,\n",
              "        0.62226362],\n",
              "       ...,\n",
              "       [0.14327761, 0.35689071, 0.28627252, ..., 0.93671422, 0.74434833,\n",
              "        0.05569425],\n",
              "       [0.12394122, 0.86452569, 0.56517272, ..., 0.93693043, 0.30697797,\n",
              "        0.21804504],\n",
              "       [0.3432727 , 0.13070061, 0.45842125, ..., 0.2545313 , 0.60975184,\n",
              "        0.18803827]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA5B_qgZGg6i"
      },
      "source": [
        "Initial state is all-zero vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGcJwIvhGeMH",
        "outputId": "7c3be04e-424a-41fc-d0d3-556c40a7305c"
      },
      "source": [
        "state_t = np.zeros((out_feature))\n",
        "state_t"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkrjyLIeGwOD"
      },
      "source": [
        "Initialize weight randomly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E1YtkCBGuBd"
      },
      "source": [
        "W = np.random.random((out_feature, input_feature))\n",
        "U = np.random.random((out_feature, out_feature))\n",
        "b = np.random.random((out_feature))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeBJyUTNIw3m"
      },
      "source": [
        "Let's implement RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ4Eov4UIvfl"
      },
      "source": [
        "successive_output = []\n",
        "i = 0\n",
        "for input_t in inputs:\n",
        "  output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b) # Combines input with the current state to obtain the current output\n",
        "  successive_output.append(output_t)\n",
        "  state_t = output_t # Update state of the network for the next timestep\n",
        "\n",
        "# The final output is a 2D tensor of shape (timesteps, output_features)\n",
        "final_output_sequence = np.concatenate(successive_output, axis=0)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DloBniQQLSmm"
      },
      "source": [
        "Issues:\n",
        "\n",
        "*  Too simplistic for real life usecases\n",
        "*  It is not possible to learn long term dependencies with SimpleRNN. This is due to *vanishing gradient problem* - as you add more layers to the network with many layer, it eventually becomes untrainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mQvMG_LMFVv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}