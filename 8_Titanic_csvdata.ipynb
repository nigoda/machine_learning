{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.Titanic_csvdata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEhFMCYKF2/c0TnViJI9Ay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigoda/machine_learning/blob/main/8_Titanic_csvdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_X0dHas4Ess"
      },
      "source": [
        "**How to laod CSV Data from a file into tf.data.Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAopV49Y0FsR"
      },
      "source": [
        "try:\n",
        "  # % tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwJzLtm243fo"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSwp0kLC5c1E"
      },
      "source": [
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLAN6jvy7__E"
      },
      "source": [
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teayclNw61bP"
      },
      "source": [
        "# Make numpy values earier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtUFBZeR7Y7w"
      },
      "source": [
        "## **Load data**\n",
        "To start, let's look at the top of the CSV file to see how it is formatted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB5zluen7PPA",
        "outputId": "62f8c80c-bc1d-4cd4-d825-22933909b3b7"
      },
      "source": [
        "!head {train_file_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
            "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
            "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
            "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
            "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
            "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
            "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
            "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
            "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
            "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmskevLQ8o7_"
      },
      "source": [
        "You can laod this using.pandas, and pass the Numpy arrays to tensorFlow. If you need to scale up to a large set of files, or need a loader that integrates with TensorFlow and tf.data then use the tf.data.experimental.make_cvs_dataset function:\n",
        "\n",
        "The only column you need to identify explicitly is the one with the value that the model is intended to predict.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkKV2te69cuK"
      },
      "source": [
        "LABEL_COLUMN = 'survived'\n",
        "LABEL = [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McSj7UB79vS1"
      },
      "source": [
        "Now read the CSV data from  the file and create a dataset.\n",
        "(For the full documentation, see t.data.experimental.make_csv_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAB6i5T9uY3"
      },
      "source": [
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size = 5, #Artificially small to make example easier to show.\n",
        "      label_name =LABEL_COLUMN,\n",
        "      na_value = '?',\n",
        "      num_epochs = 1,\n",
        "      ignore_errors = True,\n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvs7X9Q7_ZYt"
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key, value.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIe7pf3q_4Dc"
      },
      "source": [
        "Each item in the dataset is a batch, represented as a tuple of (many examples, many lables). The data from the example is organized in column-based tensors(rather than row-based tensor), each with as many element as the batch size(12 in this case).\n",
        "\n",
        "It might help to see this yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQrz6KhOAiRh",
        "outputId": "005ee3d2-9478-421d-e8f0-c7c07b437734"
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'female' b'female' b'male' b'male']\n",
            "age                 : [28. 38. 38. 36. 47.]\n",
            "n_siblings_spouses  : [2 0 0 0 0]\n",
            "parch               : [0 0 0 0 0]\n",
            "fare                : [ 23.25   80.    227.525   7.896  34.021]\n",
            "class               : [b'Third' b'First' b'First' b'Third' b'First']\n",
            "deck                : [b'unknown' b'B' b'C' b'unknown' b'D']\n",
            "embark_town         : [b'Queenstown' b'unknown' b'Cherbourg' b'Southampton' b'Southampton']\n",
            "alone               : [b'n' b'y' b'y' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIrg1icFA1c_"
      },
      "source": [
        "As you can see, the columns in the CSV are named. The dataset constructor will pick these names up automatically. If the file you are working with does not contain the column names in the first line, pass then in a list os string of the column_names argumnet in the make csv dataset function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL_LnP_0g-1J",
        "outputId": "b7c6aadc-8caa-4c7d-dcf9-491d78b9dd8a"
      },
      "source": [
        "CSV_COLUMN = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare','class', 'deck','embark_town', 'alone']\n",
        "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMN)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'female' b'female' b'female']\n",
            "age                 : [19. 39. 34. 28. 21.]\n",
            "n_siblings_spouses  : [0 0 0 1 0]\n",
            "parch               : [0 0 1 0 0]\n",
            "fare                : [ 10.5    0.    23.   133.65   7.75]\n",
            "class               : [b'Second' b'First' b'Second' b'First' b'Third']\n",
            "deck                : [b'unknown' b'A' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'Queenstown']\n",
            "alone               : [b'y' b'y' b'n' b'n' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqrBafPGA1Jq",
        "outputId": "e17efe50-7e52-40b2-ccc2-ee4450c4aa32"
      },
      "source": [
        "SELECT_COLUMNS = ['survived','age','n_siblings_spouses','class','deck','alone']\n",
        "temp_datset = get_dataset(train_file_path, select_columns =SELECT_COLUMNS )\n",
        "show_batch(temp_datset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [34. 20. 42. 28. 28.]\n",
            "n_siblings_spouses  : [0 1 1 0 0]\n",
            "class               : [b'First' b'Third' b'Second' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'F' b'unknown']\n",
            "alone               : [b'y' b'n' b'n' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRJsxsKtDR_I"
      },
      "source": [
        "## **Data preprocessing**\n",
        "\n",
        "A csv file can comtain a variety of data types. Typically you want to convert from those mixed types to a fixed length vector before feeding the data into your model.\n",
        "\n",
        "TensorFlow has a built-in system for describing common input conversion:tf.feature_column.\n",
        "\n",
        "You can preprocess your data using any tool you like(like nltk or sklearn), and just pass the processed output to TensorFlow.\n",
        "\n",
        "The primary advanatage of doing the preprocessing inside your model is that when you export the model it includes the preprosessing. This way you can passa the raw data directly to your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCaysSX9EvnA"
      },
      "source": [
        "### **Continuous data**\n",
        " If your data is already in an apropriate numeric formate,, you can pack the data into a vector passinf it off the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tyuPvfHA0BW",
        "outputId": "0f65e278-ca84-48f2-d9a3-2f2f2b55d5b7"
      },
      "source": [
        " SELECT_COLUMNS = ['survived','age','n_siblings_spouses','parch','fare']\n",
        " DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
        " temp_dataset = get_dataset(train_file_path,\n",
        "                           select_columns = SELECT_COLUMNS,\n",
        "                           column_defaults = DEFAULTS)\n",
        " \n",
        " show_batch(temp_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [80. 49. 28. 31. 28.]\n",
            "n_siblings_spouses  : [0. 0. 0. 0. 0.]\n",
            "parch               : [0. 0. 0. 0. 0.]\n",
            "fare                : [30.     0.    35.5   13.     7.896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5uRs7KqGXRN"
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95PLTvdQGjLu"
      },
      "source": [
        "Here's a simple function that will pack together all the columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3cb1xZmGhcj"
      },
      "source": [
        "def pack(features, label):\n",
        "  return tf.stack(list(features.values()), axis=-1), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUoTUY4wHNJr"
      },
      "source": [
        "Apply this to each element of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNUAzQvHUUH",
        "outputId": "5cd65a75-747b-4059-c136-b816ac9ed10f"
      },
      "source": [
        "packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "for features, labels in packed_dataset.take(1):\n",
        "  print(features.numpy())\n",
        "  print()\n",
        "  print(labels.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[36.     1.     2.    27.75 ]\n",
            " [18.     0.     1.     9.35 ]\n",
            " [38.     0.     0.    80.   ]\n",
            " [37.     1.     0.    26.   ]\n",
            " [28.     0.     0.     7.775]]\n",
            "\n",
            "[0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puvVQRMCIvTI"
      },
      "source": [
        "If you have mixed datatypes you may want to separate out these simple-numeric fileds. The tf.feature_column api can handle them, but this incurs some overhead and should be avoided unless really necessary. Swirch back to the mixed dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkfQjl7vJW-r",
        "outputId": "c17ef6e4-53a2-4832-8141-3f4619a285c8"
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'male' b'female' b'male' b'male']\n",
            "age                 : [28. 30. 28. 35. 21.]\n",
            "n_siblings_spouses  : [1 0 0 0 0]\n",
            "parch               : [0 0 0 0 0]\n",
            "fare                : [24.    27.75  79.2   26.     7.775]\n",
            "class               : [b'Second' b'First' b'First' b'Second' b'Third']\n",
            "deck                : [b'unknown' b'C' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Cherbourg' b'Cherbourg' b'Cherbourg' b'Southampton' b'Southampton']\n",
            "alone               : [b'n' b'y' b'y' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlcQ3L_rJ3Nm",
        "outputId": "1ba908d8-d578-4ea5-d792-00aab9e45d35"
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))\n",
        "example_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('age',\n",
              "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([47., 28., 35., 63., 30.], dtype=float32)>),\n",
              "             ('n_siblings_spouses',\n",
              "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 0., 0.], dtype=float32)>),\n",
              "             ('parch',\n",
              "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 0., 0.], dtype=float32)>),\n",
              "             ('fare',\n",
              "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([52.554,  7.787,  7.896,  9.587, 13.   ], dtype=float32)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Og-lfkkTRc",
        "outputId": "e1dab1e4-fd06-4699-cfda-d512f132dc3c"
      },
      "source": [
        "labels_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 0, 1, 0], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6najAEckJ__9"
      },
      "source": [
        "So define a more general preprocessor that selects a list of numeric features and packs them into a single column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBGy5JoEKPrY"
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "  \n",
        "  def __call__(self, features, labels):\n",
        "    numeric_freatures = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_freatures]\n",
        "    numeric_features = tf.stack(numeric_features, axis = -1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6EUwqDAL9Ir"
      },
      "source": [
        "NUMERIC_FEATURES = ['age', 'n_siblings_spouses','parch','fare']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpK8T0sM2SQ",
        "outputId": "50b0d1d7-49b7-461c-b9f7-1a8135bb7c01"
      },
      "source": [
        "show_batch(packed_train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'female' b'female' b'male']\n",
            "class               : [b'First' b'First' b'First' b'First' b'Third']\n",
            "deck                : [b'E' b'C' b'E' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton']\n",
            "alone               : [b'y' b'n' b'n' b'n' b'y']\n",
            "numeric             : [[ 47.      0.      0.     38.5  ]\n",
            " [ 36.      1.      0.     78.85 ]\n",
            " [ 39.      1.      1.     79.65 ]\n",
            " [ 45.      1.      1.    164.867]\n",
            " [ 36.      0.      0.      7.896]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrYuz-fTtC87",
        "outputId": "d613a142-a1a8-48a3-b37a-48f0008d7f7a"
      },
      "source": [
        "show_batch(packed_test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'male' b'male' b'male' b'female']\n",
            "class               : [b'Third' b'Third' b'Third' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Queenstown' b'Southampton' b'Southampton' b'Southampton']\n",
            "alone               : [b'n' b'y' b'y' b'y' b'n']\n",
            "numeric             : [[ 5.     4.     2.    31.388]\n",
            " [28.     0.     0.     7.738]\n",
            " [21.     0.     0.     8.05 ]\n",
            " [43.     0.     0.     6.45 ]\n",
            " [21.     1.     0.     9.825]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr7yBAkklBGy"
      },
      "source": [
        "example_batch, labels_batch = next(iter(packed_train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggGbJjGXNeRB"
      },
      "source": [
        "### **Data Normalization**\n",
        "\n",
        "Continuous data should always normalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "LS0TZzPANtot",
        "outputId": "d828510b-9315-46be-9c6d-0677fe8dac34"
      },
      "source": [
        "import pandas as pd\n",
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a16qrO9TOBXu"
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQmDw8pwOSFc"
      },
      "source": [
        "def normalize_numeric_data(data, mean ,std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q8EKxjEOz4a"
      },
      "source": [
        "Now create a numeric column, The tf.feature_columns.numeric_column API accepts a normalizer_fn argument, which will be run on each batch.\n",
        "\n",
        "Bind the MEAN and STD to normalizer fn using funtools.partial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuaGsnFmOyEW",
        "outputId": "263c526d-bfee-4a52-994a-a25ac9ccfe1c"
      },
      "source": [
        "# See what you just created.\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7f5c052c2510>, mean=array([29.631,  0.545,  0.38 , 34.385]), std=array([12.512,  1.151,  0.793, 54.598])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJpuJpCRG71"
      },
      "source": [
        "When you train the model, include this feature column to select and block of numeric data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D3fcz-KRSj8",
        "outputId": "ca9a07e3-24e8-477a-cd95-802230b25381"
      },
      "source": [
        "example_batch['numeric']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[16.   ,  0.   ,  0.   ,  9.5  ],\n",
              "       [21.   ,  0.   ,  0.   , 10.5  ],\n",
              "       [27.   ,  1.   ,  0.   , 21.   ],\n",
              "       [41.   ,  0.   ,  5.   , 39.688],\n",
              "       [28.   ,  1.   ,  0.   , 15.85 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE0d8nTNUDWP",
        "outputId": "5601adae-abe5-4ca0-a198-640820ea6e02"
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_column)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.089, -0.474, -0.479, -0.456],\n",
              "       [-0.69 , -0.474, -0.479, -0.437],\n",
              "       [-0.21 ,  0.395, -0.479, -0.245],\n",
              "       [ 0.909, -0.474,  5.827,  0.097],\n",
              "       [-0.13 ,  0.395, -0.479, -0.339]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP9g3gjElOkY"
      },
      "source": [
        "The mean based normalization used here requires knowing the mean of each column ahead of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ANag43AldMf"
      },
      "source": [
        "### **Categorical data**\n",
        "\n",
        "Some of the columns in the CSV data are categorical columns. That is, the content should be one of a limited set of options.\n",
        "\n",
        "Use the tf.feature_column API to create a collection with a tf.feature_column.indicator_column for each categorical colunmn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ktncaPVlcTR"
      },
      "source": [
        "CATEGORIES = {\n",
        "    'sex' : ['male','female'],\n",
        "    'class' : ['First','Second','Third'],\n",
        "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town' : ['Cherbourg', 'Southhampton','Queenstown'],\n",
        "    'alone' : ['y', 'n']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXB15FIKnBD4"
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "      key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1qn-Qdyn5i8",
        "outputId": "a9b32777-0cc6-4d98-b2f4-961ae4456ab3"
      },
      "source": [
        "# See what you just created\n",
        "categorical_columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('First', 'Second', 'Third'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Cherbourg', 'Southhampton', 'Queenstown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('y', 'n'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--3U2ym5oJD4",
        "outputId": "0d2d0759-2128-4963-de29-6965eae73686"
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEVI8Qfvoj8w"
      },
      "source": [
        "This will be become part of a data processing input later when you build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrn5iQ9Boxne"
      },
      "source": [
        "### **Combined preprocessing layer**\n",
        "\n",
        "Add the two feature column collections and pass them to a tf.keras.layers.DenseFeature to create an input layer that will extract and preprocessing both input types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM8Y3PzKpRsd"
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDHoldsBqAnl",
        "outputId": "6d899011-c8bd-4c07-bcdd-ff34e6bc3d89"
      },
      "source": [
        "print(preprocessing_layer(example_batch).numpy()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.     0.     0.     0.     1.     0.     0.     0.     0.     0.\n",
            "  0.     0.     0.     0.     0.     0.     0.     0.    -1.089 -0.474\n",
            " -0.479 -0.456  1.     0.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvjSXO44qNRs"
      },
      "source": [
        "### **Building the model**\n",
        " BUild a tf.keras.Sequential,starting with the preprocessing_layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3epu4SKqZrd"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLnjH3ClrOwL"
      },
      "source": [
        "### **Train, evaluate and predict**\n",
        "\n",
        "Now the model can be instantiated and trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAeZtuZ9refF"
      },
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSH4BSsTrrH3",
        "outputId": "0e398cd7-519e-4163-8fb3-9df5133a982c"
      },
      "source": [
        "model.fit(train_data, epochs = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('class', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>), ('numeric', <tf.Tensor 'IteratorGetNext:4' shape=(None, 4) dtype=float32>)])\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('class', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>), ('numeric', <tf.Tensor 'IteratorGetNext:4' shape=(None, 4) dtype=float32>)])\n",
            "Consider rewriting this model with the Functional API.\n",
            "126/126 [==============================] - 1s 2ms/step - loss: 0.5761 - accuracy: 0.6941\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8108\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8255\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8281\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8206\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8398\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8478\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8653\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8539\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8609\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8573\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8516\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8495\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8548\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8359\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8521\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8810\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8771\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8736\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5c04702da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTz3Hkqpr03M",
        "outputId": "13ea08b2-0361-4a5e-93ab-2fef0fb353c7"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8333\n",
            "\n",
            "\n",
            "Test Loss 0.4398212134838104, Test Accuracy 0.8333333134651184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFW6N13jsqPT",
        "outputId": "12821ba0-f7d6-40e2-df71-b7bc64a3ee43"
      },
      "source": [
        "#Use tf.keras.Model.predict to infer label on a batch or a dataset of batches.\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "# print(predictions)\n",
        "# show some results\n",
        "for prediction, survived in zip(predictions[:10],list(test_data)[0][1][:10]):\n",
        "  print('Predicted survival : {:.2%}'.format(prediction[0]),\n",
        "             \" | Actual outcome : \",\n",
        "        (\"SURVIVED\" if bool(survived) else \"DIED\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted survival : 11.02%  | Actual outcome :  SURVIVED\n",
            "Predicted survival : 25.95%  | Actual outcome :  SURVIVED\n",
            "Predicted survival : 10.99%  | Actual outcome :  DIED\n",
            "Predicted survival : 22.44%  | Actual outcome :  DIED\n",
            "Predicted survival : 88.92%  | Actual outcome :  SURVIVED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzZpwFL0wH24",
        "outputId": "8697d11f-a0ca-491f-b565-5764fdab7cd5"
      },
      "source": [
        "print(survived)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}